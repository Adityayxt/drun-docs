---
hide:
  - toc
---

# 功能特性

模型微调的功能特性参见下表：

| 一级功能 | 二级功能 | 描述 |
| ------- | ------ | ---- |
| 数据集 | 可视化创建数据集 | 提供直观的界面，支持创建训练、验证和测试数据集 |
| | 格式 | 支持 Alpaca 格式和 ShareGPT 格式的数据集。Alpacaga 支持指令监督微调、预训练、偏好训练、KTO、多模态数据集；ShareGPT 支持指令监督微调、偏好训练和 KTO 数据集 |
| | S3存储支持 | 支持从S3存储中直接拉取文件，提升数据接入的便捷性 |
| | 本地文件上传 | 支持本地文件上传，提供多样化的数据接入方式 |
| 分布式微调实验 | 微调方法 | 支持 LoRA、全量微调（full）、冻结微调（freeze）等多种模型微调方式的可视化管理 |
| | 训练阶段 | 支持（增量）预训练、多模态指令监督微调、奖励模型训练、PPO训练、DPO训练、KTO训练、ORPO训练等多种集成方法  |
| | 实时监控 | 支持查看微调过程中的学习率、训练损失和验证损失等关键数据，实时监控模型训练状态 |
| | 查看任务日志 | 支持查看微调过程中的日志信息 |
| 支持的基础模型 | 支持的模型 | 包括 LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Qwen2-VL、Yi、Gemma、Baichuan、ChatGLM、Phi 等等 |
