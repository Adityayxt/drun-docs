question,answer,source
What is the Edge Native Application Guidelines White Paper?,The Edge Native Application Guidelines white paper is a document released by the IoT Edge Working Group that explores the definition of edge native and the similarities and differences between "cloud native" and "edge native.",
What open source projects are included in DCE 5.0 Community Edition?,"The open source software included in the DCE Community Edition is:\n\ncloudtty: Kubernetes web console, easy to use\nClusterpedia: Kubernetes multi-cluster resource encyclopedia, has been selected for CNCF sandbox incubation, and has been deployed to production by China Mobile and others\nFerry: Kubernetes Multi-cluster communication components eliminate multi-cluster complexity\nHwameiStor: Highly available local storage solution, faster, stronger and more reliable. It has been selected into the CNCF Panorama and is applying for Sandbox\nKLTS: for k8s (latest version - 0.03), etc. Continuous maintenance of more than 10 versions\nKubean: Full life cycle management tool for containerized clusters, applying for Landscape\nKWOK: Simulating thousands of kubelets\nMerbridge: Using eBPF to accelerate service mesh, has been selected into the CNCF Panorama and Sandbox \nSpiderpool: Cloud native network IPAM automated management software. It is recommended to be used as a plug-in for Underlay CNI. It is applying for Landscape and Sandbox\nPublic image acceleration: Accelerate the download of foreign images\nThe above is just the tip of the iceberg of ""DaoCloud Daoke"" technology. There are more projects.",
What is KWOK?,"KWOK is the abbreviation of Kubernetes WithOut Kubelet, which helps users build a cluster of thousands of nodes in a few seconds and simulate thousands of real nodes with a small amount of resources.",
What scenarios is Karmada used for?,"Karmada is a project used in multi-cloud and hybrid cloud scenarios to achieve high availability of applications across data centers, cross-availability zones, and cross-clusters.",
What are VictoriaMetrics?,"VictoriaMetrics is a fast, cost-effective and scalable monitoring solution and time series database, often used with the Prometheus+AlertManager+Grafana solution.",
How many enhancements were added in Kubernetes 1.27?,60 enhancements were added in Kubernetes 1.27.,
How does Cilium achieve the socket layer acceleration effect?,"Cilium implements socket layer acceleration based on eBPF technology. eBPF technology stores socket information through mapping, and uses helper functions to achieve the ability to redirect data packets to the peer socket layer.",
What is KLTS?,"KLTS (Kubernetes Long Term Support) is a long-term support version of Kubernetes independently maintained by DaoCloud, aiming to provide enterprises with more stable and reliable Kubernetes deployment options.",
What is Chaos Mesh?,"Chaos Mesh is a cloud-native chaos engineering practice project designed to provide a complete chaos testing solution for Kubernetes applications. It can help users simulate various failure scenarios, such as network outages, application crashes, and node failures.",
What is Security Profiles Operator (SPO)?,"Security Profiles Operator (SPO) is a Kubernetes operator that simplifies the management of seccomp, SELinux, and AppArmor profiles. It can document these configuration files from scratch, often involving integration with large CI/CD systems.",
How to use Chaos Mesh?,"After installing Chaos Mesh, you need to install and authorize the account. After logging in, you can execute the chaos test scenario. For specific usage, please refer to the official documentation.",
How to make pv and pvc?,"Create a PersistentVolumeClaim (PVC) and define the amount of storage to be used, and create a PersistentVolume (PV) to accommodate the amount of storage defined in the PVC. An example is as follows:\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\nname: mysql-pv-claim\nlabels:\napp: mysql\nspec:\naccessModes:\n- ReadWriteOnce\nresources:\nrequests :\nstorage: 20Gi\napiVersion: v1\nkind: PersistentVolume\nmetadata:\nname: my-pv-volume\nspec:\ncapacity:\nstorage: 20Gi # This is the environment variable size\nvolumeMode : Filesystem # It is the mode of the file system \n​ accessModes:\n- ReadWriteOnce# means that it can only be read and written by a single machine\n​ hostPath:\n​ path: /data/mysqldata# This is the path mounted to the host\n​ type: """" # here It's a type, if not, don't write it\n```",
How to install nfs server?,The NFS server can be installed and enabled using the following command:\n```\nsudo dnf install nfs-utils\nsudo systemctl enable --now nfs-server\n```,
What is Chaos Mesh?,Chaos Mesh is a cloud-native chaos engineering platform that can simulate and test various failure and failure recovery scenarios in production environments to improve application robustness and stability.,
How to modify the seccomp configuration file and test the results of the changes?,"You can use the `jq` command to modify the JSON format configuration file, and then use the `-p [profile file]` flag to specify the new profile file path to run the application for testing, for example: `sudo ./spoc run -p /tmp/no -uname-profile.json ./main`.",
How to run seccomp configuration file using `spoc run`?,Use the command `sudo ./spoc run [binary file]` to run the application's seccomp configuration file and log which system calls are blocked or allowed.,
How to generate original seccomp configuration file using `spoc`?,"Use the `--type`/`-t` `raw-seccomp` flag to generate a raw seccomp configuration file (in JSON format), for example: `sudo ./spoc record --type raw-seccomp ./main`",
What is `spoc`? What functions does it have?,"`spoc` is a utility for recording and testing seccomp configuration files. It supports generating original seccomp configuration files, and can modify the configuration files and use `spoc run` for testing.",
What is Security Profiles Operator?,Security Profiles Operator is a Kubernetes operator that supports centralized management of various security profiles in Kubernetes.,
How do I use spoc to run a binary that has a seccomp profile applied?,"Use the `run` subcommand of the `spoc` command line tool, for example `sudo ./spoc run ./main`, where `main` is the application binary to which the seccomp configuration file has been applied. The profile location can be specified using the `--profile/-p` flag.",
How can I disable or customize basic system calls in the generated seccomp configuration file?,"Base system calls can be disabled using the `--no-base-syscalls/-n` flag in `spoc record`, or customized using the `--base-syscalls/-b` command line flag.",
How to record seccomp configuration file using spoc?,"Use the `record` subcommand of the `spoc` command line tool, for example `sudo ./spoc record ./main`, where `main` is the application binary file that needs to record the seccomp configuration file.",
What is one of the key features of the Security Profiles Operator?,"Documenting seccomp, SELinux and AppArmor configuration files from scratch is one of the key features of this Operator.",
What is Security Profiles Operator?,"Security Profiles Operator is a feature-rich Kubernetes Operator that simplifies the management of seccomp, SELinux, and AppArmor profiles.",
What is the cloud native panorama? What does it do?,"The cloud native panorama is a reference map maintained by CNCF that summarizes and categorizes mature and widely used products and solutions with best practices in the community. It provides a reference for enterprises to build cloud native systems and has extensive influence in cloud computing R&D, operation and maintenance and other fields.",
What is CNCF? What does it do?,"CNCF stands for Cloud Native Computing Foundation. It is committed to cultivating and maintaining a vendor-neutral open source ecosystem, promoting cloud native technology, and making it more popular and mature.",
What is observability? What role does it play in the cloud native space?,"Observability refers to actively observing various types of data associated with applications to achieve comprehensive monitoring and troubleshooting. In the field of cloud native, observability has become one of the hottest topics, which can replace traditional system monitoring and bring better management and operation and maintenance experience to cloud native applications.",
What is the development background of DaoCloud Enterprise 5.0?,"DaoCloud Enterprise 5.0 is a new generation of cloud native operating system. Its research and development background is mainly to meet the needs of rapid deployment, operation and maintenance, and management of cloud native applications.",
What problems does the emergence of the Merbridge CNI model solve?,"The emergence of Merbridge CNI mode can better adapt to the functions of the service mesh, solving problems such as the inability to adapt to the Sidecar Annotation injected into Istio, the inability to exclude certain port or IP segment traffic, and the inability to process external traffic sent to Pods.",
What are the popular cloud native open source projects at KubeCon + CloudNativeCon Europe 2022?,"Many popular cloud-native open source projects emerged at KubeCon + CloudNativeCon Europe 2022, including Istio, Kubernetes, Prometheus, Envoy, Harbor, etc.",
What is CloudTTY? What problems does it solve?,"CloudTTY is a cloud-native open source project based on kubernetes, which solves a series of functional requirements of web page command lines under permission control.",
What is Clusterpedia? What does it do?,Clusterpedia is an open source project that can perform complex resource retrieval on multiple clusters through kubectl. Its main function is to perform information retrieval in a multi-cloud environment.,
What is KubeCon + CloudNativeCon Europe 2022? What are the popular cloud native open source projects at this event?,"KubeCon + CloudNativeCon Europe 2022 is the world’s top cloud native flagship conference. This event involved many popular cloud-native open source projects, such as Cluster-api, Karmada/Clusternet, etc.",
"""Cloud-edge collaboration hyper-converged all-in-one machine"" was jointly launched by which two companies? What is its goal?","""Cloud-edge collaboration hyper-converged all-in-one machine"" is jointly launched by Huawei and Shanghai Daoke Network Technology Co., Ltd. Its goal is to bring cloud native capabilities to the edge, provide real-time virtual digital world experience, and realize a true cloud-edge integrated metaverse.",
What is CloudTTY? What platform is it based on?,"CloudTTY is a cloud-native open source project based on the Kubernetes platform, which solves the functional requirements under ""web command line"" permission control on a series of clusters.",
What is Clusterpedia? What problem does it solve?,Clusterpedia is a CNCF sandbox project for complex resource retrieval across clusters. It solves the increasingly complex internal resource management and retrieval of multiple clusters and the huge challenges faced by multi-cloud management.,
In which quadrant of the CNCF is Merbridge included? Why did it launch CNI mode?,Merbridge is included in the Service Mesh quadrant of the Orchestration & Management layer in the CNCF Cloud Native Panorama. Merbridge launched the CNI mode to better adapt to the functions of the service mesh so as to better handle the traffic inside and outside the Pod.,
What module capabilities does DCE provide?,"DaoCloud Enterprise 5.0 is a high-performance and scalable cloud-native operating system with the following main features and advantages:\n\nMulti-cloud orchestration: supports cross-cloud resource retrieval, multi-cloud application deployment, release and operation and maintenance capabilities, helping enterprises build Multi-cloud, hybrid cloud digital infrastructure. \nData middleware service: Cloud-native local storage capabilities designed for stateful applications, providing middleware management capabilities to achieve self-service application, elastic expansion, high concurrency processing, and stable and high availability of data services. \nMicroservice governance: Provides non-intrusive traffic management functions to achieve full life cycle management and ensure the continuous availability of microservice applications. \nObservability: Comprehensive collection of service data based on technical means such as logs, links, indicators, and eBPF, and query of all cluster and load observation data through a unified control plane to achieve second-level fault location. \nApp Store: Includes software products from ecological partners in ten major fields such as big data, AI, and middleware, and provides out-of-the-box ecological application software to create a complete solution system. \nApplication delivery: Achieve more sophisticated management and operation of applications through self-service cloud migration, flexible tenant system, and automated application construction and deployment. \nXinchuang Heterogeneous: Compatible with domestic chips and servers, supporting Xinchuang operating system and Xinchuang application ecosystem, ensuring the stability and reliability of Xinchuang application operating environment. \nCloud-edge collaboration: Extend cloud-native capabilities to the edge to solve the need to uniformly complete large-scale application delivery, operation and maintenance, and management and control on massive edge and end devices, achieving true cloud-edge integration. \nCloud native base: Provides cloud native computing, network, storage and other capabilities to break through K8s API performance bottlenecks and enable large-scale enterprise users to concurrently use multiple clusters.",
Which event did "DaoCloud Daoke" host? What content does this activity mainly share?,"""DaoCloud Daoke"" hosted the event ""On Dao Native｜Cloud Native Digital Ecosystem Private Meeting·Shanghai"". This event started from cloud native thinking and technology and shared the application and practice of cloud native in medical and artificial intelligence.",
What are Kubeans? What does it rely on as the underlying technology?,Kubean is a cluster lifecycle management tool. It uses Kubespray as the underlying technology dependency.,
What is the cloud-native local storage system HwameiStor? In which CNCF Cloud Native Panorama quadrant is it included?,HwameiStor is "DaoCloud's independent open source cloud-native local storage system. It is included in the Cloud Native Storage quadrant of the RunTime layer in the CNCF Cloud Native Panorama.,
What is CNCF?,CNCF (Cloud Native Computing Foundation) is a non-profit organization dedicated to promoting cloud native technology and aims to promote the development and popularization of cloud native technology through open source projects.,
How to pull dependent images (domestic acceleration)?,Execute the following command to pull the dependencies,
How to pull dependent images (default)?,Execute the following command to pull the dependent image:\n```bash\nVERSION=1.18.20-lts.2\nREPOS=ghcr.io/klts-io/kubernetes-lts\nkubeadm config images pull --image-repository ${ REPOS} --kubernetes-version v${VERSION}\n```,
How to automatically start Kubelet at boot?,Execute the following command to automatically start Kubelet at boot:\n```bash\nsystemctl enable kubelet\n```,
How to install KLTS (Debian based distribution)?,Execute the following command to install:\n```bash\napt-get install kubeadm kubelet kubectl\n```,
How to install KLTS (Red Hat based distribution)?,Execute the following command to install:\n```bash\nyum install kubeadm kubelet kubectl\n```,
"How to set up the software source of KLTS (Debian-based distribution, domestic acceleration)?",Execute the following code to set up the software source for downloading KLTS:\n```bash\ncurl https://raw.githubusercontent.com/wzshiming/github-hosts/master/hosts >>/etc/hosts\nVERSION=1.18.20- lts.2\ncat << EOF > /etc/apt/sources.list.d/klts.list\ndeb [trusted=yes] https://raw.githubusercontent.com/klts-io/kubernetes-lts/deb- v${VERSION} stable main\ndeb [trusted=yes] https://raw.githubusercontent.com/klts-io/others/deb stable main\nEOF\napt-get update\n```,
"How to set up the software source of KLTS (a distribution based on Red Hat, domestically accelerated)?",Execute the following code to set up the software source for downloading KLTS:\n```bash\ncurl https://raw.githubusercontent.com/wzshiming/github-hosts/master/hosts >>/etc/hosts\nVERSION=1.18.20- lts.2\ncat << EOF > /etc/yum.repos.d/klts.repo\n[klts]\nname=klts\nbaseurl=https://raw.githubusercontent.com/klts-io/kubernetes-lts /rpm-v${VERSION}/\$basearch/\nenabled=1\ngpgcheck=0\n[klts-other]\nname=klts-others\nbaseurl=https://raw.githubusercontent.com/klts-io /others/rpm/\$basearch/\nenabled=1\ngpgcheck=0\nEOF\nyum makecache\n```,
How to set up the software repository for KLTS (Debian-based distribution)?,Execute the following code to set the software source for downloading KLTS:\n```bash\nVERSION=1.18.20-lts.2\ncat << EOF > /etc/apt/sources.list.d/klts.list\ndeb [trusted =yes] https://raw.githubusercontent.com/klts-io/kubernetes-lts/deb-v${VERSION} stable main\ndeb [trusted=yes] https://raw.githubusercontent.com/klts-io /others/deb stable main\nEOF\napt-get update\n```,
How to set up the software repository for KLTS (Red Hat based distribution)?,Execute the following code to set the software source for downloading KLTS:\n```bash\nVERSION=1.18.20-lts.2\ncat << EOF > /etc/yum.repos.d/klts.repo\n[klts]\ nname=klts\nbaseurl=https://raw.githubusercontent.com/klts-io/kubernetes-lts/rpm-v${VERSION}/\$basearch/\nenabled=1\ngpgcheck=0\n[klts-other ]\nname=klts-others\nbaseurl=https://raw.githubusercontent.com/klts-io/others/rpm/\$basearch/\nenabled=1\ngpgcheck=0\nEOF\nyum makecache\n```,
How to install KLTS?,KLTS provides installation methods based on deb and rpm software sources. You can set up the KLTS software source and use the corresponding commands for installation.,
How to build containerd?,```bash\nVERSION=1.5.4\nwget -c https://github.com/containerd/containerd/releases/download/v${VERSION}/containerd-${VERSION}-linux-amd64.tar.gz \ntar xvf containerd-${VERSION}-linux-amd64.tar.gz -C /usr/local/\nmkdir /etc/containerd/ && containerd config default > /etc/containerd/config.toml\nwget -c -O /etc/systemd/system/containerd.service https://raw.githubusercontent.com/containerd/containerd/main/containerd.service\nsystemctl start containerd && systemctl enable containerd\n````,
"For containerd, where can I find instructions for setting up a Docker repository and installing the containerd.io package for my respective Linux distribution?",Find instructions for setting up the Docker repository and installing the containerd.io package for your respective Linux distribution in [Installing the Docker Engine](https://docs.docker.com/engine/install/#server).,
How to install Docker based on Debian distribution?,Execute the following command to install Docker based on Debian distribution:\n```bash\napt-get install docker.io\n```,
How to install Docker based on Red Hat distribution?,Execute the following command to install Docker based on the Red Hat distribution:\n```bash\nyum install docker\n```,
What is containerd?,"containerd is a cloud-oriented, open and portable container runtime, open sourced by Docker, used to manage the container life cycle, integrate with high-level orchestration systems (such as Kubernetes), etc.",
How to install containerd?,You can install the `containerd.io` package from the official Docker repository or build it from source. Please refer to the article for specific methods.,
How to install Docker based on Debian distribution?,Execute the command `apt-get install docker.io` to install Docker based on the Debian distribution.,
How to install Docker based on Red Hat distribution?,Execute the command `yum install docker` to install Docker based on the Red Hat distribution.,
What container runtime does Kubernetes use to run containers in Pods?,"Kubernetes uses the Container Runtime Interface (CRI) to interact with the container runtime of your choice. By default, kubeadm uses docker as the container runtime. kubelet integrates with Docker through the built-in `dockershim` CRI. If you do not specify a runtime, kubeadm automatically attempts to detect the runtimes already installed on the system.",
How to disable Selinux?,"Selinux can be temporarily shut down by executing the `setenforce 0` command. If a permanent shutdown is required, edit `/etc/sysconfig/selinux` and replace `SELINUX=enforcing` with `SELINUX=disabled`.",
Why do you need to disable swap partition?,"In order for the kubelet to work properly, you must disable the swap partition.",
How to set node name?,Use the command `hostnamectl set-hostname your-new-host-name` to set the node name and add `127.0.0.1 $(hostname)` and `::1 $(hostname)` to the `/etc/hosts` file .,
What ports need to be opened on the working node?,The working node needs to open TCP inbound port 10250 and ports 30000-32767 (default NodePort service port range).,
Which ports need to be opened on the control plane nodes?,"Control plane nodes need to open TCP inbound ports 6443, 2379-2380, 10250, 10251, and 10252.",
How to check network adapter?,"If you have more than one network adapter and your Kubernetes components are unreachable through the default route, we recommend that you add IP routing rules in advance so that the Kubernetes cluster can complete the connection through the corresponding adapter.",
Why is it important to check the uniqueness of the MAC address and product_uuid on the node?,"Kubernetes uses the MAC address and product_uuid to determine the unique node in the cluster. If these values are not unique on each node, the installation may fail.",
What is the minimum amount of memory and CPU required for each host in the cluster?,Each host requires at least 2 GB of memory or more and a CPU of 2 cores or more.,
What does KLTS mean?,KLTS (Kubernetes Long Term Support) is Kubernetes independently maintained by DaoCloud.,
Which Linux distributions is the Kubernetes project based on?,"The Kubernetes project provides common instructions for Linux distributions based on Debian and Red Hat, as well as some distributions that do not provide a package manager.",
"In this example, what is the maximum number of failures allowed before success?","In this example, up to 3 failures are allowed before success.",
"When checking status, which command should be used?","When checking status, the kubectl describe StatusCheck status-check-example command should be used.",
What is the address of the HTTP request?,The address of the HTTP request is http://10.1.3.210:30028.,
What is the mode of StatusCheck?,The mode of StatusCheck is Synchronous.,
What is StatusCheck used for in this example?,StatusCheck in this example is used to check whether an HTTP service is running properly.,
How can I better understand some of the ways to use Chaos Mesh? What are the references?,"You can install and practice using Chaos Mesh, and refer to the official documentation for more understanding. The official document URL is https://chaos-mesh.org/zh/docs/.",
What are the StatusCheck types in Chaos Mesh? Please give examples respectively.,The StatusCheck type in Chaos Mesh has two modes: Continuous and Synchronous. The YAML format and status checking methods of Continuous type and Synchronous type are different. Please refer to the original article to understand.,
What are the settings switches in the Chaos Mesh settings?,"The settings of Chaos Mesh include login/logout, theme color, Chinese and English settings and other settings switches.",
"In Chaos Mesh, can the details of archived experiments, plans, and workflow objects be viewed?","The details of archived experiments, plans, and workflow objects cannot be viewed because the archived resource objects no longer exist in Kubernetes.",
Where is Chaos Mesh data stored?,Chaos Mesh data is stored in the database.,
How to create a plan that will be executed regularly at 05 minutes every hour and delete the selected nginx Pod in it?,You can create a plan that will be executed regularly at 05 minutes every hour and delete the selected nginx Pod through the following yaml definition:\n```yaml\napiVersion: chaos-mesh.org/v1alpha1\nkind: Schedule\nmetadata: \nname: schedule-delay-example\nnamespace: default\nspec:\nschedule: "5 * * * *"\nhistoryLimit: 2\nconcurrencyPolicy: Allow\ntype: "PodChaos"\npodChaos:\naction: "pod-kill" \nmode: one\nselector:\nnamespaces:\n- default\nlabelSelectors:\n"app.kubernetes.io/instance": "nginx"\n````,
How to create a PodChaos experiment and delete selected nginx Pods?,You can create a PodChaos experiment and delete the selected nginx Pod through the following yaml definition: \n```yaml\napiVersion: chaos-mesh.org/v1alpha1\nkind: PodChaos\nmetadata:\nname: pod-kill-example2\nnamespace: default\nspec:\naction: pod-kill\nmode: one\nselector:\nnamespaces:\n- default\nlabelSelectors:\n"app.kubernetes.io/instance": "nginx"\n````,
What does the Chaos Mesh dashboard look like?,"The dashboard of Chaos Mesh displays information related to fault injection, including experiment list, experiment details, plan list, plan details, workflow list, etc.",
What fault injection types does Chaos Mesh support?,"The fault injection types supported by Chaos Mesh include: PodChaos, NetworkChaos, IOChaos, TimeChaos, and KernelChaos.",
"In addition to container image pulling and API query limitations, what other factors may affect the startup speed of Pods on nodes?","Other factors mentioned in the article that may affect Pod startup include container runtime, disk speed, and CPU and memory resources on the node.",
"To speed up container startup, which feature replaces recursively changing every file on the volume by mounting the volume with the correct SELinux label?",SELinux mount option relabeling feature.,
"In Kubernetes v1.27, what is the default value of `memoryThrottlingFactor` in kubelet configuration?",The default value is 0.9.,
What does the feature gating called MemoryQoS introduced in Kubernetes v1.22 do?,Memory,
How to switch nodes to use event-based lifecycle change detection?,You can explicitly switch to event-based life cycle change detection to speed up kubelet startup.,
"In Kubernetes v1.27, to what extent does kubelet increase the default `kubeAPIQPS` and `kubeAPIBurst` values?",were increased to 50 and 100 respectively.,
Why do we need to increase the kubelet default API query limit per second?,"In a node with multiple Pods, kubelet needs to synchronize Pod status and prepare ConfigMap, Secret or volume, which requires large bandwidth to access kube-apiserver. Increasing the kubelet default API query limit per second can speed up Pod startup.",
How to limit the number of parallel container image pulls on a node?,You can set the `maxParallelImagePulls` field in the kubelet configuration to limit the number of parallel image pulls.,
How to enable parallel container image pulling?,Set the `serializeImagePulls` field in the kubelet configuration to false.,
Why does parallel container image pulling help speed up pod startup on nodes?,"Parallel container image pulling can pull multiple images at the same time, thereby speeding up the image pulling time.",
"In the comparison of eBPF socket acceleration and TCP/IP stack latency, which one is better?","In the comparison of eBPF socket acceleration and TCP/IP stack latency, eBPF socket acceleration is better than the conventional TCP/IP stack, and the performance is nearly 50% better than the conventional TCP/IP stack.",
Does the size of the request message size have an impact on the latency of eBPF socket acceleration?,The size of the request message size has no impact on the latency of eBPF socket acceleration.,
What protocol level overhead is eliminated when using eBPF for acceleration?,"When using eBPF for acceleration, any protocol level overhead (slow start, congestion avoidance, flow control, etc.) is eliminated by redirecting packets from the source socket's transmit queue to the destination socket's receive queue.",
How does the performance compare between TCP/IP stack and eBPF socket acceleration when Nagle algorithm is disabled?,"In the performance comparison of the TCP/IP stack and eBPF socket acceleration with the Nagle algorithm disabled, the throughput gain of the TCP/IP stack completely disappears. At this point, eBPF socket acceleration, with its low overhead, far exceeds the throughput of the TCP/IP stack with Nagle's algorithm enabled. But as sent messages get larger and larger, exceeding the MSS, the TCP/IP stack loses its batch processing advantage. At these large packet send sizes, eBPF socket acceleration still outperforms the regular TCP/IP stack due to its low overhead.",
What is Nagle's algorithm?,"The Nagle algorithm is used to solve the problem of congestion caused by the proliferation of small data packets in slow networks. In this algorithm, as long as a TCP segment is not confirmed when it is smaller than the TCP MSS size, a batch transmission data operation will be performed.",
Which eBPF programs and mappings does Cilium use to implement socket layer acceleration?,"Cilium uses the following eBPF procedures and mappings to implement socket layer acceleration:\n- eBPF mapping: Cilium_sock_ops (Type: BPF_MAP_TYPE_SOCKHASH): Stores socket information. \n- eBPF program: \n- obpf_sockmap (type: BPF_PROG_TYPE_SOCK_OPS): intercepts the socket establishment connection operation in the system and stores the socket information to cilium_sock_ops. \n- obpf_redir_proxy (type: BPF_PROG_TYPE_SK_MSG): intercept the sendmsg system call in the system, extract the key, and redirect the data directly to the peer socket.",
How does Cilium accelerate when the source and target are on the same node?,"When Cilium processes the source and destination on the same node, it redirects the traffic directly to the destination socket at the socket layer, thus directly bypassing the entire TCP/IP protocol stack and achieving acceleration.",
What is the overall architecture of Cilium?,"Cilium's overall architecture includes multiple components, among which the daemon component implements socket layer acceleration. The daemon component will start a Pod on each node in the cluster, so the socket acceleration effect will be applied to each node.",
Why do applications called on the same node need socket layer acceleration?,"In order to achieve faster service speed, when two applications that call each other are deployed on the same node, each request and return needs to go through the socket layer, TCP/IP protocol stack, data link layer, and physical layer. If requests and returns bypass the TCP/IP protocol stack and directly redirect data packets to the opposite socket at the socket layer, it can greatly reduce the time it takes to send data packets, thus speeding up service.",
What technology is Cilium based on to achieve socket layer acceleration?,Cilium implements socket layer acceleration based on eBPF technology.,
"When deploying application configurations on the Karmada control plane, how to specify which clusters the application is scheduled to?","In the application configuration, you can specify which clusters the application is scheduled to by using clusterNames in the propagation policy.",
Which controllers and schedulers in Karmada are involved in cross-cluster failure recovery?,"During the cross-cluster fault recovery process, the ReplicaScheduler controller, ReplicaReconciler controller, PropagationReconciler controller and PodHook scheduler in Karmada are involved.",
How does the Divided failover strategy work?,"When a cluster fails, the scheduler and controller work together to try to migrate the failed cluster copy to another cluster that is running normally.",
What two methods does Karmada fault recovery support?,Karmada fault recovery supports Duplicated and Divided methods.,
What is Karmada’s goal?,"Karmada is designed to provide convenient automation for multi-cluster application management in multi-cloud and hybrid cloud scenarios, with key features such as centralized multi-cloud management, high availability and fault recovery.",
What are the advantages and disadvantages of VictoriaMetrics compared to Prometheus?,"Advantages:\n1. Performance advantages;\n2. Better horizontal expansion and high availability solutions;\n3. Data multi-tenancy capabilities. \nDisadvantages:\n1. There is no WAL log similar to Prometheus;\n2. In order to optimize storage to a greater extent, some data accuracy will be lost.",
How to view VictoriaMetrics cache metrics on the Grafana dashboard?,"On the Grafana dashboard, you can view the current memory usage and cache hit rate for each type of cache. Displays each type of cache metrics on the panel using the vm_cache_size_bytes, vm_cache_size_max_bytes, vm_cache_requests_total, vm_cache_misses_total, and vm_cache_entries metrics.",
"In VictoriaMetrics, on which page can each type of cache metric be exported?","In VictoriaMetrics, each type of cache metrics can be exported on the ""/metrics"" page.",
In which directory is the VictoriaMetrics cache stored? How can I delete these caches on next startup?,"VictoriaMetrics' cache is stored in the ""<-storageDataPath>/cache"" directory, where it is stored during a normal shutdown. If you need to delete these caches on the next startup, you can do so by placing the reset_cache_on_startup file in the ""<-storageDataPath>/cache"" directory before restarting VictoriaMetrics.",
In what form does VictoriaMetrics support adding labels to push data?,"VictoriaMetrics supports adding labels to push data in the form of label=""value"", using pushmetrics.extraLabel configuration.",
What are the advantages of VictoriaMetrics compared to Prometheus?,"VictoriaMetrics provides excellent performance, horizontal expansion, high availability solutions and data multi-tenancy.",
How to manage VictoriaMetrics cache?,"VictoriaMetrics uses various internal caches and supports deleting the cache by placing a reset_cache_on_startup file in the ""<-storageDataPath>/cache"" directory before restarting VictoriaMetrics. At the same time, VictoriaMetrics uses various in-memory caches to speed up data ingestion and query performance, and cache metrics can be exported on the ""/metrics"" page.",
What data push methods does VictoriaMetrics support?,"When indicators cannot be pulled, VictoriaMetrics supports pushing indicators in Prometheus data format through push mode. You can use ""-pushmetrics.url"" to configure the push address, ""-pushmetrics.extraLabel"" to configure the extension label, and ""- pushmetrics.interval"" configures the push period.",
How does VictoriaMetrics monitor?,"VictoriaMetrics exports internal metrics in Prometheus exposion format on the ""/metrics"" page, and exposes currently running queries and their execution times on the ""/api/v1/status/active_queries"" page, and on the ""/api/v1/status/top_queries"" page The query with the longest execution time is exposed on the ""/api/v1/status/TSDB"" page, and TSDB statistics are returned on the ""/api/v1/status/TSDB"" page.",
How is VictoriaMetrics stored?,"VictoriaMetrics will store time series data in a MergeTree-like data structure. On insert, VictoriaMetrics accumulates up to 1s of data and dumps it to the `<storageDataPath>/data/small/YYYY_MM/` subdirectory on disk, forming a `part with the following name pattern: ""rowsCount_blocksCount_minTimestamp_maxTimestamp""`. Each part consists of two ""columns"": value and timestamp. Additionally, part contains index files for searching specific series in value and timestamp files. Parts are periodically merged into larger parts, and the generated parts are constructed in the `<storageDataPath>/data/{small, big}/YYYY_MM/tmp` subdirectory.",
How to deduplicate data in VictoriaMetrics?,"VictoriaMetrics will deduplicate according to the value configured by ""-dedup.minScrapeInterval"", leaving only one original sample and retaining the data with the largest timestamp in the configuration period. Eliminating duplicate data can reduce disk space usage when multiple identically configured vmagent or Prometheus instances write data to the same VictoriaMetrics instance.",
What data formats does VictoriaMetrics support for import and export?,"VictoriaMetrics supports the use of dedicated Agent interfaces to import data (Prometheus remote_write API, DataDog submit metrics API, Graphite plaintext protocol, OpenTSDB telnet put protocol, OpenTSDB http api/put protocol) and the use of unified interfaces to import data (/api/v1/import export json format , /api/v1/import/csv exports csv format, /api/v1/import/native exports binary format). At the same time, it also supports exporting data using the export interface (/api/v1/export exports json format, /api/v1/export/csv exports csv format, /api/v1/export/native exports binary format).",
How to force merge of VictoriaMetrics data?,"You can use ""<http://victoriametrics:8428/internal/force_merge?partition_prefix=YYYY_MM>"" to perform forced data compression. The request result will be returned immediately in an asynchronous form, and the data compression task will be performed in the background. When data needs to be deleted immediately, forced merge can be used to trigger data deletion.",
How to manually delete data in VictoriaMetrics?,"You can use ""<http://<victoriametrics-addr>:8428/api/v1/admin/tsdb/delete_series?match[>]=<timeseries_selector_for_delete>"". The storage space of deleted time series is not released immediately, but is released during the subsequent background merging of data files. Note that for previous months of data, background merging may never occur, so no storage space is freed for historical data. In this case, forcing a merge may help free up storage space.",
How to configure VictoriaMetrics data retention time?,"This can be configured using the ""-retentionPeriod"" command line flag, which takes a number followed by a time unit character ""-h (ours), d (ays), w (eeks), y (ears)"". If the time unit is not specified, months are assumed. For example, ""-retentionPeriod=3"" means the data will be stored for 3 months and then deleted. The default retention period is one month.",
How to eliminate duplicate data?,"VictoriaMetrics is configured based on the ""-dedup.minScrapeInterval"" command line flag, which takes a number that represents the data retained within a given time interval. The default value is 0.01s, which can be increased to eliminate duplicate data.",
What data import and export methods does VictoriaMetrics support?,"VictoriaMetrics supports the use of dedicated Agent interfaces to import data: Prometheus remote_write API, DataDog submit metrics API, Graphite plaintext protocol, OpenTSDB telnet put protocol and OpenTSDB http api/put protocol. At the same time, it also supports importing using unified interfaces: /api/v1/import (export json format), /api/v1/import/csv (export csv format) and /api/v1/import/native (export binary format). Correspondingly, you can also use the export interface to export data: /api/v1/export (export json format), /api/v1/export/csv (export csv format) and /api/v1/export/native (export binary format) .",
How to perform data deletion and forced merge?,"You can use the API provided by VictoriaMetrics to delete and force merge data. For specific operation methods, please refer to the description in the article.",
What is the architecture of VictoriaMetrics?,"The VictoriaMetrics cluster consists of the following services: vmstorage, vminsert, vmselect. Each service can be scaled independently and run on the most suitable hardware. Vmstorage nodes do not know each other, do not communicate with each other, and do not share any data. At the open source level, VictoriaMetrics provides the following components: vmui, vmagent, vminsert, vmstorage, vmselect, vmalert, vmbackup, vmrestore.",
What data sources does VictoriaMetrics support?,"VictoriaMetrics supports the following data sources: Prometheus, DataDog agent, InfluxDB-compatible agents such as Telegraf, Graphite-compatible agents such as StatsD, OpenTSDB-compatible agents.",
How to quickly connect to Prometheus to obtain data sources?,The following configuration can be added to the VictoriaMetrics configuration file:\n```yaml\nremote_write:\n- url: http://<victoriametrics-addr>:8428/api/v1/write\nglobal:\nexternal_labels:\ndatacenter: dc-123\n```,
What are the advantages of VictoriaMetrics over Prometheus?,"The advantages of VictoriaMetrics over Prometheus include: simple deployment, using the vmbackup/vmrestore tool to easily and quickly back up instant snapshots to S3 or GCS; read and write performance up to 20 times better than InfluxDB and TimescaleDB; memory usage ratio under millions of time series data InfluxDB is 10 times smaller and 7 times smaller than Prometheus, Thanos or Cortex; data is highly compressed and requires up to 7 times less storage space than Prometheus, Thanos or Cortex.",
What are VictoriaMetrics?,"VictoriaMetrics is a fast, cost-effective and scalable monitoring solution and time series database that can be used as a long-term storage for Prometheus and supports the Prometheus query API. It can be used as a replacement for Prometheus in Grafana.",
How to determine the cause of slow Pod startup?,"Metrics and logs can be analyzed and factors such as container runtime, disk speed, CPU and memory resources on the node, etc. can be analyzed to determine the cause of slow Pod startup.",
What is the SELinux mount option remarking feature?,"SELinux mount option relabeling is a Kubernetes feature that speeds up container startup by mounting volumes with the correct SELinux labels, rather than recursively changing every file on the volume.",
What new indicators and log information related to Pod startup are added in Kubernetes v1.26?,"A new histogram metric named pod_start_sli_duration_seconds is added to Kubernetes v1.26 to display Pod start delay SLI/SLO details. In addition, kubelet logs now display more timestamp information related to Pod startup.",
How to set memory QoS?,Memory can be executed in the Pod by setting the cgroupv2 memory.high value,
What is memory QoS?,Memory,
What are the capabilities of the execution controller?,"The ability of the execution controller is to create, update or delete the resources that actually need to be delivered stored in the work of the corresponding execution namespace of the member cluster in the corresponding member cluster.",
What is the core logic of binding controller?,"The core logic of the binding controller is to remove orphan work, ensure that the work expected by rb (ResourceBinding) meets expectations, aggregate the status of the work, record it in the status of rb (ResourceBinding), and update the resource template status based on the aggregated status of rb (ResourceBinding).",
What is the core logic of gracefulEviction controller?,"The core logic of the gracefulEviction controller is to ensure that the new replica is ready on a cluster that meets the requirements before removing the graceful eviction task, that is, only the old resources scheduled to the failed cluster can be deleted.",
Which controllers are used to coordinate Karmada fault recovery?,"Karmada fault recovery is completed collaboratively by the binding controller, gracefulEviction controller and execution controller.",
What is Karmada?,Karmada is a Kubernetes cross-cluster scheduler that can schedule applications in different Kubernetes clusters.,
Under what circumstances will the rescheduling operation of Karmada scheduler be triggered?,"When the sum of all replicas under rb.spec.clusters (resource scheduling cluster results) is not equal to rb.spec.replicas (resource expected replicas), the scheduler considers this to be an expansion or contraction operation, thus triggering a rescheduling operation.",
What does the taint-manager controller do?,"When the taint-manager controller detects that the cluster has a taint with effect NoExecute,\nit will obtain all namespace-level and cluster-level rb (ResourceBinding) on the cluster, and then put them into the corresponding eviction processing queue. \nThe eviction processing consumer (worker) will determine whether to obtain the pp (PropagationPolicy) corresponding to rb (ResourceBinding) to see if there is cluster taint tolerance in pp (PropagationPolicy). If the cluster taint tolerance and cluster taint in pp (PropagationPolicy) matches,\nthen skip it directly and consider that the resources on the cluster do not need to be evicted. Otherwise, eviction is considered necessary.",
How to add effect as NoSchedule and NoExecute taint?,"In the cluster conntroller, when the condition status of type Ready in conditions is ""False"", call the UpdateClusterControllerTaint function to add stains with effects NoSchedule and NoExecute.",
Under what circumstances does the clusterStatus controller update the conditions of the cluster object?,"When the cluster is offline and the initialized condition status is not 'True', it is considered that the conditions of the cluster resource object need to be updated. The condition status of type Ready in conditions will be modified to 'False'.",
Why do we need clusterStatus controller?,The clusterStatus controller is a controller used to monitor and maintain cluster status. It writes status conditions to the cluster object based on the health status of the cluster for subsequent use by the scheduler and eviction components.,
Which controller in Karmada is responsible for executing work under the namespace and creating resources in the member clusters according to the corresponding member clusters?,The execution controller is responsible for executing work under the namespace corresponding to the member cluster and creating resources in the member cluster.,
Which controller in Karmada is responsible for ensuring that the resource status on the new scheduling cluster is healthy before removing resource objects on the evicted cluster?,The gracefulEviction controller is responsible for ensuring that the resource status on the new scheduling cluster is healthy before removing the resource objects on the eviction cluster.,
Which controller in Karmada is responsible for determining whether a failed cluster needs to be marked as unschedulable and unexecutable?,"The cluster controller is responsible for determining whether the faulty cluster needs to be marked with unschedulable and unexecutable stains, and determines which stain to add based on the condition status of type Ready in conditions.",
How does Karmada sense cluster status?,"Karmada detects the '/readyz' and '/healthz' of the member cluster kube-apiserver through the clusterStatus controller, obtains the online status and health status of the member cluster, and synchronizes them to the cluster resource object of the control plane.",
How is failure recovery implemented in Karmada?,"Failure recovery in Karmada is achieved by marking the cluster status as unavailable when a cluster fails, adding two taints, and then removing the application and scheduling it to another cluster that meets the requirements. Failover ensures high availability and continuity of user services.",
How to use propagation strategy and coverage strategy to control resource delivery in Karmada?,"Propagation and override policies can be defined using the propagationPolicy field in the yaml file. The propagationPolicy field includes two subfields: staticWeightList and dynamicWeightList. Control of propagation strategy and coverage strategy is achieved by defining these two fields. Among them, staticWeightList can control the spread of resources between clusters, and dynamicWeightList can control the scheduling of resources within the cluster.",
How to implement failover in Karmada?,"When a cluster failure occurs, Karmada will automatically adjust the replicas on the remaining member clusters to meet the user's overall replica expectations and achieve cluster-level failure recovery. When the failed cluster recovers, the transferred copy will remain unchanged, the resources on the original scheduling cluster will be deleted, and the resources will not be scheduled back to the failed cluster.",
What happens after a cluster failure in Karmada?,"When a cluster fails or a user no longer wants to run applications on the cluster, the cluster status is marked as unavailable and two taints are added. When a cluster failure is detected, the controller removes the application from the failed cluster. The removed applications will then be scheduled to other clusters that meet the requirements.",
What is Xinchuang heterogeneity?,"Xinchuang Heterogene adopts Xinchuang cloud-native technology architecture, is compatible with domestic chips and servers, shields the complexity of the underlying heterogeneous infrastructure, realizes flexible scheduling of hybrid heterogeneous clusters, and ensures the stability and high reliability of Xinchuang application operating environment.",
What capabilities does DCE’s cloud-native base provide?,"DCE's cloud-native base provides cloud-native computing, network, storage and other capabilities, supports the full life cycle management of clusters from deployment, version upgrades, certificate changes, configuration changes, recycling, etc., enabling ultra-large-scale enterprise users to use multiple clusters concurrently.",
What does DCE’s cloud-edge collaboration capability mean?,"DCE's cloud-edge collaboration capability extends cloud-native capabilities to the edge, using edge cluster and edge node models to move the computing power of the data center downwards and the computing power of end devices upward to achieve true integration of the cloud and edge.",
Who is DCE's app store targeting?,"DCE's application store is aimed at the actual business needs of enterprises. It includes software products from ecological partners in ten major fields such as big data, AI, and middleware, and provides out-of-the-box ecological application software.",
What is DCE?,"DaoCloud Enterprise 5.0 is a high-performance and scalable cloud-native operating system with the following main features and advantages:\n\nMulti-cloud orchestration: supports Xinchuang heterogeneity, edge-cloud collaboration, and multi-cloud orchestration, and can be deployed on any infrastructure, Provide a consistent and stable experience in any environment. \nMicroservice architecture: Integrate cutting-edge service grid and microservice technologies to implement observability throughout every traffic generation, helping to gain insight into detailed indicators of clusters, nodes, applications and services. \nDevOps development and operation: natively supports the DevOps development and operation model to achieve standardization and automation of the entire application delivery process. \nFlexible and scalable: Each product module of DCE 5.0 is independently decoupled, flexibly upgraded, and business-agnostic. It can be openly connected with over a hundred cloud-native ecological products to form a complete solution system. \nObservability: Provides a one-stop graphical dashboard to visualize application health status through dynamic dashboards and topology maps. \nMiddleware integration: Native integration of various selected databases and middleware makes operation and maintenance management more efficient. \nLego building block-like modular design: You can flexibly build your own cloud-native containerized comprehensive platform according to the specific needs of the enterprise to cope with a large number of application scenarios. \nEasy to install: Community version and commercial version are available, and installation is easy. \nDCE 5.0 can help enterprises define digital boundaries, build a solid and reliable digital foundation, and unleash cloud-native productivity.",
What functions does the application delivery module of DCE 5.0 implement?,"The application delivery module of DCE 5.0 implements self-service cloud migration through a consistent and generalizable application delivery process, supports a flexible tenant system, dynamically adapts to user organizational structure planning and real-time resource allocation, and is based on cloud-native CI/CD pipelines to integrate The rich tool chain supports efficient concurrent execution and flow of pipelines, automatically completes the construction and deployment of applications, and innovatively introduces Gitops and progressive delivery capability systems to achieve more sophisticated management and operation of applications.",
What technical means is the observability module of DCE 5.0 based on?,"The observability module of DCE 5.0 is based on logs, links, indicators, eBPF and other technical means to comprehensively collect service data, obtain in-depth request link information, dynamically observe and multi-dimensionally control real-time changes in clusters, nodes, applications and services, and Through the unified control plane, all clusters and load observation data can be queried, and topology analysis technology is introduced to visually grasp the application health status.",
What functions does the microservice governance module of DCE 5.0 provide?,"The microservice governance module of DCE 5.0 provides non-intrusive traffic management functions, supports seamless access to traditional microservices, cloud native microservices and open source microservices frameworks, and supports microservices from development, deployment, access, observation, and operation. Dimension's full life cycle management provides high-performance cloud-native microservice gateways and introduces independent open source eBPF grid acceleration technology.",
What capabilities does the multi-cloud orchestration module of DCE 5.0 provide?,"The multi-cloud orchestration module of DCE 5.0 provides unified centralized management that supports multi-cloud and hybrid cloud, provides cross-cloud resource retrieval and cross-cloud application deployment, release and operation and maintenance capabilities, realizes efficient management and control of multi-cloud applications, and provides elastic application expansion based on cluster resources. shrink, achieve global load balancing, have fault recovery capabilities, and effectively solve multi-cloud application disaster recovery issues.",
What are the modules of DCE 5.0?,"The modules of DCE 5.0 include: container management, global management, observability, application workbench, multi-cloud orchestration, microservice engine, service mesh, middleware, image warehouse, cloud native network and cloud native storage.",
What cloud environments does DCE 5.0 support?,"DCE 5.0 delivers a consistent, stable experience across any infrastructure and any environment, supporting heterogeneous clouds, edge clouds and multi-cloud orchestration.",
What is DaoCloud Enterprise 5.0?,"DaoCloud Enterprise 5.0 is a high-performance, scalable cloud-native operating system that provides a consistent, stable experience on any infrastructure and any environment, supporting heterogeneous clouds, edge clouds, and multi-cloud orchestration.",
What challenges do internal platform implementers need to be aware of?,Internal platform implementers need to be aware of the following challenges: 1. Platform teams must treat their platforms like products and develop them with users; 2. Platform teams must carefully choose priorities and initial collaboration with application development teams; 3. Platform teams must seek buy-in from business leadership and demonstrate impact on the value stream.,
What tasks does the platform team need to pay attention to?,"The platform team needs to pay attention to the following tasks: 1. Research platform user needs and plan Roadmap; 2. Promote and disseminate the value of the platform within the enterprise; 3. Manage and develop interfaces, including portals, APIs, documents, templates, and CLI tools.",
What attributes do platform teams need to pay attention to?,Platform teams need to pay attention to the following attributes: 1. Platform as a Product; 2. User experience; 3. Documentation and quick start; 4. Self-service; 5. Reduce cognitive load; 6. Optional and composable ;7. Safe by default.,
What are the processes for platform maturity?,"Platform maturity goes through the following process: 1. Product developers provide capabilities on demand and use them immediately to run the system; 2. Product developers provide service spaces on demand and use them to run pipelines and tasks; 3. Third-party software Administrators provide dependencies on demand and easily install and run them; 4. Product developers provide complete environments on demand from templates, such as web development or MLOps; 5. Product developers and managers observe the functionality of deployed services, performance and cost.",
What is an internal platform?,"An internal platform is the “thinnest logical layer” of consistency that provides resources and capabilities to teams within an enterprise to meet the organization’s requirements. They deliver a consistent, compliant experience through a single capability or combination of capabilities, ultimately making it easier and more efficient for their users to deliver valuable products.",
What process has the internal platform gone through to mature?,"The internal platform may go through the following processes in use: providing the capability and consistent experience of a single service, providing service space, providing dependencies, providing templates and environments, and observing the functionality, performance, and cost of deployed services.",
What is an internal platform?,"Internal platform refers to the ability to provide services to internal users of the enterprise in a way that can be easily integrated by applications. For example, an internal platform can provide self-service APIs, project templates, and a consistent user experience.",
Why do you need a platform?,"By investing in a platform, companies can realize benefits such as reducing cognitive load on product teams, improving product reliability and resiliency, accelerating product development and delivery, reusing shared platform tools and knowledge, and governing associated risks.",
What is the value of platform engineering in cloud computing?,"Platform engineering in cloud computing helps enterprises realize the long-promised value of cloud computing, such as rapid product releases, portability across infrastructures, more secure and resilient products, and higher developer productivity.",
What is platform engineering?,"Platform engineering refers to the form of work that has emerged as an explicit form of collaboration in the enterprise to provide the foundational capabilities, frameworks, and experiences that facilitate and accelerate the work of internal users (such as application developers, data scientists, and information processors).",
What are the references for Karmada?,"Karmada's reference materials include Karmada source code, Karmada official documentation, cloud native multi-cloud application tool - Karmada Overview, cloud native multi-cloud application tool - Karmada controller and cloud native multi-cloud application tool - Karmada scheduler, etc.",
How does Karmada perform in its CNCF project contribution?,"Among the CNCF project contributions that the author has contributed to, Karmada is currently the project with the fastest issue responses and the fastest processing of code merge requests.",
What features did the Karmada community discuss in the latest meeting?,"In the latest community meeting, there was discussion about enhancing Failover features and adding more configuration capabilities for Failover in the propagation strategy.",
Does Karmada support users to customize whether to schedule back to the restored cluster? Why?,"The current direction of the community is that in the future, customers may be provided with the ability to choose whether to reschedule. Considering the impact of rescheduling on application stability, there is currently no reason to schedule back to the original cluster.",
How does Karmada achieve cluster-level high availability?,"Karmada implements cluster-level high availability based on mechanisms such as failover mode, container lifecycle hooks, and client load balancing.",
How does Karmada achieve multi-cloud management across cloud service providers?,Karmada combines Kubernetes clusters from different cloud providers into a virtual super cluster by connecting them to a control plane.,
What are the core features of Karmada?,"Karmada's core function is inter-cluster application orchestration and scheduling management, supporting multi-cloud service providers, multiple container orchestration tools and multiple deployment modes.",
What is Karmada?,Karmada is an open source multi-cloud application orchestration and scheduling platform designed to enable applications based on cloud-native technologies to be deployed and managed across multiple cloud providers.,
What does the Execution controller in Karmada do?,"The Execution controller is responsible for creating, updating, or deleting the resources that actually need to be delivered stored in the Work of the corresponding execution namespace of the member cluster in the corresponding member cluster.",
How to implement failover in Karmada?,"Failover is completed by multiple controllers and schedulers. When a cluster fails, other clusters will take over this part of the work to ensure high availability of the application.",
What does the Scheduler controller in Karmada do?,"The Scheduler controller is responsible for scheduling the Work submitted by users to the appropriate cluster, and splitting or fully deploying copies according to the scheduling policy.",
What does the ClusterPlan controller in Karmada do?,The ClusterPlan controller is responsible for converting the ClusterPlan submitted by the user into the corresponding Kubernetes resources and creating these resources in the cluster.,
What can Karmada do?,"Karmada enables deployment, orchestration and scheduling of applications across cloud platforms, and supports features such as failover and replica splitting.",
Which Kubernetes version is Karmada based on?,"Karmada version release is not directly related to Kubernetes version release, but the current stable version is developed based on Kubernetes 1.19.0.",
What is Karmada?,"Karmada is an open source, cloud-native multi-cloud application management platform that enables the deployment, orchestration and scheduling of applications on multiple cloud platforms.",
What is a container image? What does it contain?,"container image is an immutable, static file that contains the dependencies for creating a container. These dependencies may include an executable binary, system libraries, system tools, environment variables, and other necessary platform settings.",
What is ConfigMap? What does it do?,"ConfigMap is an API object used to save non-confidential data into key-value pairs. When used, it can be used as an environment variable, a command line parameter, or a configuration file in a storage volume. ConfigMap decouples your environment configuration information from container images, making it easy to modify application configurations.",
What is a cluster?,"A cluster is a set of computing nodes that run containerized applications. In Kubernetes, clusters typically run multiple nodes to provide fault tolerance and high availability.",
What is a cloud provider? What services do they typically provide?,"cloud provider is a commercial organization or other organization that provides a cloud computing platform. Many cloud providers offer hosted infrastructure (also called Infrastructure as a Service or IaaS). For hosted infrastructure, the cloud provider is responsible for the servers, storage and network, while the user is responsible for managing the layers of software running on it, such as running a Kubernetes cluster.",
What is cloud native technology?,"Cloud native technology is the technology used to build cloud-native applications, enabling organizations to build and run scalable applications in modern dynamic environments where they adhere to the ""promise of the cloud"" and take full advantage of cloud computing.",
What is Chaos Engineering?,"Chaos engineering, or CE, is the discipline of experimenting with distributed systems in production to build confidence in the system's ability to withstand turbulence and unexpected situations.",
What is a control group?,"Control group (cgroup) is a Linux kernel feature that limits, audits, and isolates the resource usage (CPU, memory, disk I/O, network, etc.) of a group of processes.",
What is a certificate?,The certificate is a secure encrypted file used to confirm the legitimacy of access to the Kubernetes cluster.,
What is cAdvisor?,"cAdvisor (Container Advisor) is a daemon process responsible for collecting, aggregating, processing and outputting information about running containers.",
What is canary deployment?,Canary deployment is a deployment strategy that starts with two environments: one with live traffic and another containing updated code without live traffic.,
What is blue-green deployment?,"Blue-green deployment is a strategy for updating running computer systems with minimal downtime. The operator maintains two environments, called ""blue"" and ""green"". One serves production traffic (the version all users are currently using), while the other is updated.",
What is bare metal?,"Bare metal refers to a physical computer, more specifically a server, that has only one operating system.",
What is autoscaling?,Autoscaling usually refers to the system's ability to automatically scale in terms of computing resources. The auto-scaling system can automatically add resources when needed and scale to meet changing user needs.,
What is authorization?,"Authorization refers to granting users the permissions they need to complete specific tasks. Authorization takes effect through the permissions of system roles or custom roles. After users obtain specific permissions, they can operate resources or services.",
What is an audit log?,The audit log provides a history of changes made to objects in the system.,
What is Autoscaling?,"Autoscaling refers to the system's ability to automatically scale. It is usually configured based on different metrics, such as memory or processing time, and automatically adds resources when needed, scaling to meet changing user needs.",
What is an App Container?,"App Container is a container that runs part of the workload in a Pod. Unlike the Init container, it starts after the Init container has started. If a Pod does not have an Init container configured, all containers in the Pod are application containers.",
What is API-initiated eviction?,"API-initiated eviction is a process that first calls the Eviction API to create an eviction object, and then uses this object to gracefully terminate the Pod. It can directly call the Eviction API through the client of kube-apiserver to initiate eviction.",
What is Admission Controller?,"The Admission Controller intercepts requests arriving at the API server after the request passes authentication and authorization and before the object is persisted. It can perform validation and/or change operations and restrict requests to create, delete, or modify objects.",
What is Abstraction?,"Abstraction is a consumption of services that hides the details of the service, making the entire system more general and easier to understand.",
Which API version of CSIStorageCapacity was removed in v1.27?,The storage.k8s.io/v1beta1 API version of CSIStorageCapacity was removed in v1.27.,
"When KMSv2 is upgraded to Beta, what are the benefits of optimizing the reuse of DEK data encryption keys when the plug-in key ID remains unchanged?","KMSv2 is upgraded to Beta. When the plug-in key ID remains unchanged, reusing the DEK data encryption key can reduce the time and computing resource overhead required for DEK regeneration. This optimization performs re-random generation on server startup.",
To what level will SelfSubjectReview be promoted?,Promote SelfSubjectReview to Beta level.,
What stage has the AdmissionWebhookMatchConditions feature entered?,"The AdmissionWebhookMatchConditions feature has entered Alpha stage, and in v1Beta and v1 API, MatchConditions fields were added for ValidatingWebhookConfiguration and MutatingWebhookConfiguration.",
What support does Kubernetes provide for aggregate discovery in v1.27?,"In v1.27, Kubernetes provides beta support for aggregate discovery, publishing all resources supported by the cluster through /api and /apis, instead of providing them separately for each Group.",
What is ValidatingAdmissionPolicy?,ValidatingAdmissionPolicy is a new resource introduced after KEP-2876 CRD Validation Expression Language was provided in Kubernetes v1.25. It allows field validation without using Validation Webhooks and supports features such as custom matching conditions.,
"The API validation for Indexed Job has been relaxed, allowing Indexed Job to be expanded or shrunk by changing which two parameters at the same time?","API validation for Indexed Jobs has been relaxed, allowing Indexed Jobs to be expanded or shrunk by changing parallelism and completions simultaneously, but requires keeping parallelism == completions modified synchronously.",
Which functions does CronJob support for upgrading to GA?,CronJob supports the Timezone function to be upgraded to GA.,
"The StatefulSetStartOrdinal function has been upgraded to Beta, allowing the starting sequence number to be configured in StatefulSet. What does this sequence number refer to?","The StatefulSetStartOrdinal function has been upgraded to Beta, allowing the starting sequence number to be configured in the StatefulSet by default. This serial number refers to the index of the first Pod in the StatefulSet.",
What is PodDisruptionBudget and which new field has been added?,PodDisruptionBudget is a mechanism to control the number of Pods that are terminated during node maintenance or node failure. A newly added unhealthyPodEvictionPolicy field is used to specify what behavior should occur for unhealthy Pods. This field was upgraded to Beta in v1.27.,
What features does DaoCloud contribute in Kubernetes v1.27?,"DaoCloud has mainly contributed content related to sig-node, sig-scheduling and kubeadm in Kubernetes v1.27. Specifically, it includes fixing the problem of waiting time when trying to obtain leader lease, upgrading the MinDomainsInPodTopologySpread function to Beta, adding feature gate EtcdLearnerMode to Kubeadm, etc. In addition, DaoCloud has also participated in hundreds of problem fixes and feature development, and many R&D engineers have made many achievements.",
What is kubectl apply --prune function?,"The kubectl apply --prune function is a function in Kubernetes that is used to automatically clean up some objects deleted by apply yaml. This feature was introduced as Alpha in v1.5, and was redesigned and upgraded to Alpha in v1.27. The new version adds --applyset for use and can better support complex scenarios.",
What is NodeLogQuery feature gating?,NodeLog,
What are CustomResourceValidationExpressions?,"CustomResourceValidationExpressions is a rule used to validate CRDs in Kubernetes. In v1.25, CustomResourceValidationExpressions has been upgraded to Beta version. In v1.27, ValidationRule adds a new field messageExpression to better display validation prompt information.",
What is the PodTopologySpread scheduling strategy?,"The PodTopologySpread scheduling strategy is a scheduling strategy in Kubernetes that can schedule new Pod instances more evenly when rolling updates to Deployment. In v1.27, the PodTopologySpread scheduling policy can distinguish the value of the scheduling Pod label, so that new Pod instances are scheduled more evenly.",
What functionality does NodeLogQuery feature gating provide?,NodeLog,
"How does the PodTopologySpread scheduling strategy distinguish between old and new instances, and what problems can it solve?","The PodTopologySpread scheduling strategy can distinguish the value of the scheduling Pod label, so that after rolling updates, new Pod instances will be scheduled more evenly. This can solve the problem of uneven scheduling of new instances during rolling updates of Deployment.",
In which version is vertical elastic scaling of Pod resources supported?,Vertical elastic scaling of Pod resources is supported in version 1.25.,
To what state has APIServerTracing been upgraded and enabled by default?,APIServerTracing has been upgraded to Beta status and enabled by default.,
"What problem was MinimizeIPTablesRestore introduced to solve? In which version was it introduced, upgraded to Beta and enabled by default?","MinimizeIPTablesRestore was introduced to solve the performance problem of kube-proxy's iptables mode in large clusters. This feature was introduced in version 1.26, upgraded to Beta in version 1.27 and enabled by default.",
For which StatefulSet do the Retain and Delete behaviors trigger the corresponding PVC deletion action?,Only when the StatefulSet configured with the Delete policy is deleted will the corresponding PVC deletion action be triggered.,
In which version was the StatefulSetAutoDeletePVC feature introduced?,The StatefulSetAutoDeletePVC functionality was introduced in v1.23.,
Where has the domain name of the Kubernetes container image warehouse been changed to registry.k8s.io?,The domain name of the Kubernetes container image warehouse has been changed from k8s.gcr.io to registry.k8s.io.,
How many more enhancements are there in Kubernetes 1.27 than in previous versions?,"Kubernetes 1.27 tracks 60 enhancements, many more than in previous versions.",
Which version will Kubernetes 1.27 be in 2023?,Kubernetes 1.27 is the first version of 2023.,
"What are ArtifactHub, Harbor, Distribution, Porter, etc. about?","ArtifactHub, Harbor, Distribution, Porter, etc. are about artifact storage technologies. They are mainly used to store, publish and protect build artifacts for production purposes, cache and analyze third-party artifacts, store source code, etc.",
What is a thinnest viable platform (TVP)?,The thinnest viable platform is a concept that strikes a careful balance: keeping the platform small while balancing the benefits of platform acceleration and simplified software delivery.,
What roles does the platform team consist of?,"The platform team is composed of platform product managers, developers and other roles. Other roles can also become part of the platform team. These roles are responsible for developing and maintaining the interfaces and experiences for platform functionality.",
Who is the platform capability provider? What does capability include?,"platform capability provider is an organization or team that develops and maintains the capabilities provided by the platform, including infrastructure, runtime, or other support services.",
What is a platform?,A platform is an entity that integrates the capabilities required to develop and deliver software. It can provide and manage common capabilities to enable developers and operators to deliver applications and services faster.,
What is TVP?,TVP refers to the thinnest viable platform and maintains a careful balance between keeping the platform small and the platform's effect of accelerating and simplifying software delivery.,
Who will manage the platform team?,The platform team is managed by a platform product manager.,
What organizations or teams can platform capability providers be?,Platform capability providers can be external organizations or internal teams.,
What does a good platform reflect?,A good platform reflects the needs of its users.,
What metrics does Google's DORA Institute recommend tracking?,"Deployment frequency, change preparation time, service recovery time after failure, change failure rate.",
What is the ultimate goal of the platform?,The ultimate goal of the platform is to deliver business value to customers faster.,
What is Container Storage Interface (CSI)? What does it do?,"The Container Storage Interface (CSI) defines the standard interface that storage systems expose to containers. CSI allows storage driver providers to create customized storage plug-ins for Kubernetes without adding the code for these plug-ins to the Kubernetes code repository (external plug-ins). To use a storage provider's CSI driver, you first need to deploy it to your cluster. Then you can create a StorageClass that uses the CSI driver.",
What is a CronJob? What functions does it have?,"CronJob manages tasks that run regularly. Similar to a line of commands in a crontab file, the periodic scheduling task (CronJob) object uses cron format to set the schedule.",
What is Database as a Service (DBaaS)? What are its advantages?,Database as a Service (DBaaS) is a service managed by a cloud operator (public or private) that supports applications without requiring the application team to perform traditional database management functions. DBaaS allows application developers to leverage databases without having to become experts or hire a database administrator (DBA) to keep the database up to date. It helps organizations develop enterprise-grade applications faster and minimize database costs.,
What is a DaemonSet? What does it do?,"DaemonSet ensures that a copy of a Pod is running on a set of nodes in the cluster. It is used to deploy system daemon processes, such as log collection and monitoring agents, which usually must run on each node.",
What is Contour? What is its role in a microservices gateway?,"Contour is the control plane of the microservice gateway and is deployed as a control node to serve as Envoy's back-end management service capability. It provides convenient gateway configuration, supports dynamic configuration updates, and multi-cluster deployment capabilities. HTTPProxy CRD is also provided to enhance the core configuration capabilities of Kubernetes Ingress.",
What is a periodic scheduling task (CronJob)?,"Periodic scheduling tasks manage tasks that run regularly, similar to a line of commands in a crontab file. The CronJob object uses cron format to set the schedule.",
What are Container Runtime Interface (CRI) and Container Runtime (CR)?,"CRI is a set of container runtime APIs integrated with kubelet on the node. It is the main protocol for communication between kubelet and container runtime. CR is the component responsible for running containers. Kubernetes supports many container running environments, such as containerd, cri-o, etc.",
What is a Custom Resource Definition (CRD)?,"CRD is an API extension method that adds resource objects to your Kubernetes API server through customized code without compiling a complete customized API server. When Kubernetes' publicly supported API resources don't meet your needs, CRD allows you to extend the Kubernetes API on your own environment.",
What is a control plane?,"The control plane refers to the container orchestration layer, which exposes APIs and interfaces to define, deploy containers, and manage the life cycle of containers. This orchestration layer is composed of multiple different components, such as etcd, API server, scheduler, controller manager, cloud controller manager, etc.",
What are continuous delivery and continuous deployment?,"Continuous delivery is a practice in which code changes are automatically deployed to the acceptance environment (or, in the case of continuous deployment, to production). Continuous deployment goes a step further than continuous delivery by deploying completed software directly to production.",
How to install DCE 5.0 Community Edition?,"Perform the following steps:\n1. Install basic dependencies:\n````bash\ncurl -LO https://proxy-qiniu-download-public.daocloud.io/DaoCloud_Enterprise/dce5/install_prerequisite.sh\nbash install_prerequisite.sh online community \n```\n2. Download dce5-installer:\n```bash\nexport VERSION=v0.5.0\ncurl -Lo ./dce5-installer https://proxy-qiniu-download-public.daocloud. io/DaoCloud_Enterprise/dce5/dce5-installer-$VERSION\nchmod +x ./dce5-installer \n````\n3. Confirm the external reachable IP address of the node. \n4. Execute the installation:\n- If the IP address of the browser and the master node can be connected directly, execute the following command:\n````bash\n./dce5-installer install-app -z -k\n```\ n- If the IP of the master node is the internal network, please create an IP reachable from the external network in the public cloud, and allow the ingress and egress of port 32088 in the firewall rules, and execute the following command:\n```bash\n ./dce5-installer install-app -z -k $External IP:32088 # $External IP is the external IP of the master node. \n```",
How to install default storage CSI (using local storage)?,Execute the following command:\n```bash\nwget https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml # Download the CSI configuration file. \nsed -i "s/image: rancher/image: docker.m.daocloud.io\/rancher/g" local-path-storage.yaml # Replace docker.io with the actual image. \nsed -i "s/image: busybox/image: docker.m.daocloud.io\/busybox/g" local-path-storage.yaml \nkubectl apply -f local-path-storage.yaml # Apply the configuration file. \nkubectl get po -n local-path-storage -w # Wait for all Pods to be running. \nkubectl patch storageclass local-path -p "{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}" # Set local-path as default SC. \nkubectl get sc # You can see the form: local-path (default). \n```,
How to connect to other worker nodes?,"Execute the join command on other worker nodes. When executing `kubeadm init` on the above master node, the final message will be printed on the screen:\n```bash\nkubeadm join $IP of the first master: 6443 --token p...7 --discovery-token-ca- cert-hash s....x\n```\nAfter successful join, the output is similar to:\n```none\nThis node has joined the cluster:\n* Certificate signing request was sent to apiserver and a response was received.\n* The Kubelet was informed of the new secure connection details.\nRun ""kubectl get nodes"" on the control-plane to see this node join the cluster.\n```\nConfirm the node on the master node are all connected, and wait for them to change to Ready status: \n```bash\nkubectl get no -w # Wait for the node status to change to ready. \n```",
"Taking calico as an example, how to install CNI?","1. Install calico-operator first:\n```bash\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/tigera-operator.yaml\n``\ n2. Then issue the modified/configured CR:\n```bash\ncurl -LO https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/custom-resources.yaml # Download Configuration file template\ngrep cidr custom-resources.yaml #Print out the default CIDR\n# Please confirm that the CIDR in the calico configuration file is consistent with the CIDR during kubeadm init! ! ! Otherwise, please modify!!!⚠️ \nvim custom-resources.yaml # Modify the parameters in the file, such as CIDR, etc. \nkubectl apply -f custom-resources.yaml # Execute the modified configuration file. \n```\n3. Wait for the deployment to be successful: \n```bash\nkubectl get po -n calico-system -w # Wait for all Pods to be Running. \nkubectl get no # You can see that the first node has become ready. \n```",
How to configure kubeconfig file?,Execute the following command:\n```bash\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$ (id -g) $HOME/.kube/config\n```,
What is the version number of the installed Kubernetes component?,Take version 1.25.8 as an example,
"After installing Containerd, how to modify the Containerd configuration file?",```bash\n#Delete the built-in config.toml\nmv /etc/containerd/config.toml /etc/containerd/config.toml.old\n#Reinitialize the configuration\nsudo containerd config default | sudo tee /etc /containerd/config.toml\n#Update the configuration file content: use systemd as the cgroup driver and replace the pause image address\nsed -i "s/SystemdCgroup\ =\ false/SystemdCgroup\ =\ true/" /etc/containerd/ config.toml\nsed -i "s/k8s.gcr.io\/pause/k8s-gcr.m.daocloud.io\/pause/g" /etc/containerd/config.toml # Old pause address\nsed - i "s/registry.k8s.io\/pause/k8s-gcr.m.daocloud.io\/pause/g" /etc/containerd/config.toml\nsudo systemctl daemon-reload \nsudo systemctl restart containerd \nsudo systemctl enable containerd\n```,
How to uninstall Podman pre-installed on the system when installing the container runtime?,`yum erase podman buildah -y`,
What Kubernetes version is available for DCE 5.0 Community Edition?,Kubernetes: 1.25.8,
"In the Calico underlay scenario, how to help Deployment and other types of applications achieve fixed IP requirements?","Just use Spiderpool's manual IP pool function. For specific operations, please refer to the code example above.",
Can Spiderpool realize the requirement of fixed IP?,"Yes, by manually specifying an IP pool and binding it to an application, you can make the application fixedly use a specific IP in the pool.",
What is Spiderpool's IP allocation method?,"By default, Spiderpool will randomly allocate an available IP from the configured IP pool to the application.",
How to manually specify an IP pool?,"You need to first create an IP pool object, specify the IP range, and then specify the IP pool by annotating `ipam.spidernet.io/ippool` when creating the application. For specific operations, please refer to the code example above.",
How to view all IP pools in a Kubernetes cluster?,Use the command `kubectl get sp`,
How do I manually specify which IP pool an application uses?,You can add the annotation `ipam.spidernet.io/ippool` to the application's Deployment and specify which IP pool to use.,
How to manually specify an IP pool?,"You need to create a CRD resource named SpiderIPPool, and specify two parameters, spec.subnet and spec.ips, in the resource, which respectively indicate which subnet the IP pool belongs to and the fixed IP address range.",
How to use Spiderpool automatic pooling function to fix IP pool for application?,The following annotations need to be added to the application's Deployment:\n- `ipam.spidernet.io/subnet`: Specify which subnet to automatically create an IP pool and bind it to the application Pod\n- `ipam.spidernet.io/ ippool-ip-number`: Specifies the total number of IPs in the IP pool. The number is three more than the number of replicas.,
What are the main features of Spiderpool?,"Spiderpool mainly has the following features:\n- It can automatically allocate fixed IP addresses for Deployment and StatefulSet types, and the number of IP addresses can automatically expand and shrink with the number of copies\n- It can manage and configure IP pools in CRD mode, which greatly Reduce operation and maintenance costs\n- Supports Pods created by third-party controllers\n- Supports specifying different subnets for Pods with multiple network cards",
Spiderpool is designed for the IP address management needs of which network model?,Spiderpool is designed for the IP address management needs of Underlay network mode.,
Which annotation of Calico can achieve Pod-level IP fixing?,`cni.projectcalico.org/ipAddrs`.,
How does Calico enable clients outside the cluster to access Pods?,Calico BGP mode announces the route of the Pod subnet to the gateway. Clients from outside the cluster can directly access the Pod through the Pod's IP while retaining the client's source IP.,
What is Calico?,"Calico is a set of open source network and network security solutions, and is also an implementation of the Kubernetes container network solution (CNI: Container Network Interface).",
Will Linux/arm be released in Kubernetes v1.27? Why?,"Linux/arm will not be released in Kubernetes v1.27 due to problems building with golang 1.20.2. Note, arm64 is still supported.",
Which feature gating in Kubernetes has been deprecated and will be removed in a future release?,SecurityContextDeny feature gating is deprecated and will be removed in a future release.,
Which command line parameters have been removed in kube-controller-manager?,The kube-controller-manager command line parameters --enable-taint-manager and --pod-eviction-timeout have been removed.,
Which API version of CSIStorageCapacity has been deprecated and will be removed in Kubernetes v1.27?,The storage.k8s.io/v1beta1 API version of CSIStorageCapacity has been deprecated and will be removed in Kubernetes v1.27.,
What Kubernetes version changes does this article mention that need attention?,"This article mentions key Kubernetes version changes to note: IPv6DualStack external cloud provider feature gates are removed, and k8s.gcr.io redirects to registry.k8s.io.",
How to create a kind cluster?,"The steps to create a kind cluster are:\n1. Download the binary file package of kind. \n```bash\ncurl -Lo ./kind https://qiniu-download-public.daocloud.io/kind/v0.17.0/kind-linux-amd64\nchmod +x ./kind\nold_kind=$( which kind)\nif [ -f ""$old_kind"" ]; then mv ./kind $old_kind; else mv ./kind /usr/bin/kind ; fi\n```\n2. Create `kind_cluster.yaml` configuration document. \n```bash\ncat > kind_cluster.yaml << EOF\napiVersion: kind.x-k8s.io/v1alpha4\nkind: Cluster \nnodes:\n- role: control-plane \nextraPortMappings:\n- containerPort: 32088 \nhostPort: 8888 \nEOF\n```\n3. Create a K8s cluster named `fire-kind-cluster` through kind, taking k8s 1.25.3 as an example. \n```bash\nkind create cluster --image docker.m.daocloud.io/kindest/node:v1.25.3 --name=fire-kind-cluster --config=kind_cluster.yaml \n```",
How to check system resources and networking status?,You can set the -e parameter according to the command in this article to check the system resources and networking status:\n```bash\nset -e\nif [ $(free -g|grep Mem | awk "{print $2}") -lt 12 ]; then (echo "insufficient memory! (should >=12G)"; exit 1); fi\nif [ $(grep "processor" /proc/cpuinfo |sort |uniq |wc -l) -lt 8 ]; then (echo "insufficient CPU! (should >=8C)"; exit 1); fi\nif [ $(df -m / |tail -n 1 | awk "{print $4}") -lt 30720 ]; then (echo "insufficient free disk space of root partition!(should >=30G)"; exit 1); fi\nping daocloud.io -c 1 &> /dev/null || ( echo "no connection to internet! abort." && exit 1; )\necho "precheck pass.."\n```,
What do I need to install before installing DCE?,"Docker needs to be installed before installing DCE, and the version must be higher than 1.18.",
This article introduces how to install stand-alone DCE 5.0 Community Edition online on a Linux machine. What conditions are needed?,"You need a Linux machine. Recommended resources: CPU > 8 cores, memory > 12G, disk space > 100GB. Make sure the machine can connect to the public network. The operating system is CentOS7 or Ubuntu22.04.",
How to uninstall Docker Desktop?,Find Docker Desktop in the application list and uninstall it.,
How to uninstall kind?,Execute the command `rm -f $(which kind)`.,
How to confirm whether DCE 5.0 Community Edition is installed successfully?,"Execute the command `docker exec -it fire-kind-cluster-control-plane kubectl get po -A -w` to observe the Pod startup status. When you see the prompt ""DCE 5.0 Community Edition installed successfully"", you can confirm that the installation is successful.",
How to install DCE 5.0 Community Edition?,"Install dependencies: execute the command `cat <<EOF | docker exec -i fire-kind-cluster-control-plane bash ... EOF`\n- Download the dce5-installer binary: execute the command `docker exec -it fire -kind-cluster-control-plane /bin/bash`, and then execute `export VERSION=v0.5.0; curl -Lo ./dce5-installer https://proxy-qiniu-download-public.daocloud.io/DaoCloud_Enterprise/ dce5/dce5-installer-$VERSION && chmod +x ./dce5-installer && exit`\n- Install DCE 5.0 Community Edition: First obtain the local IP, and then execute the command `docker exec -it fire-kind-cluster-control -plane bash -c ""./dce5-installer install-app -z -k $myIP:8888""`.",
How to create a kind cluster?,Execute the command `kind create cluster --image docker.m.daocloud.io/kindest/node:v1.25.3 --name=fire-kind-cluster --config=kind_cluster.yaml`.,
How to create a kind configuration file?,Execute the command `cat > kind_cluster.yaml << EOF ... EOF` to create the kind_cluster.yaml file.,
How to install kind?,"Mac is an Intel chip: execute the command `[ $(uname -m) = x86_64 ]&& curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.17.0/kind-darwin-amd64` \n- Mac is an M1/ARM chip: execute the command `[ $(uname -m) = arm64 ] && curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.17.0/kind- darwin-arm64`; then execute `chmod +x ./kind` and `sudo mv kind /usr/local/bin/kind`\n- Install kind through Homebrew: install Homebrew first `/bin/bash -c ""$( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)""`, and then execute `brew install kind`",
How to adjust the resource limit of a container?,"After starting Docker Desktop, click ⚙️ in the upper right corner, open `Settings` -> `Resources`, adjust the resource limit for starting the container to 8C14G, and then click the `Apply & Restart` button.",
How to install Docker Desktop?,"Depending on the MacBook's chip (Intel or M1), install [Docker Desktop](https://docs.docker.com/desktop/install/mac-install/).",
How to confirm whether the MacBook's hardware environment meets the requirements?,"Make sure that the MacBook's CPU has at least 8 cores, the memory is at least 16G, and the remaining disk space is greater than 20G.",
In what manner does the Edge Computing Market report analyze the market?,"The Edge Computing Market Size, Share and Trends Analysis Report analyzes the edge computing market by component (hardware, software, services, edge management platform) and application differentiation (smart factory, smart city, smart retail, etc.).",
What are the groups of edge native guidelines?,"Hardware and resource management, variable connection awareness (networking), and external device connections can be considered under the broader resource and hardware management guidelines. Large-scale management of edge applications, centralized observation, and manageable infrastructure and platforms can all be classified as large-scale management criteria. The remaining guidelines include: cross-region, resource usage optimization, portability and reusability limits, resource and hardware management, and scale management.",
What are edge native applications?,"Edge-native applications are applications and services designed for the edge, with significant advantages in hardware management capabilities, external device connections, variable connection awareness, centralized observability, large-scale infrastructure and platform management, large-scale application management, cross-region, resource usage optimization, and There are a number of guidelines for things like portability and reusability.",
What guidelines should edge-native apps follow?,"Edge-native applications should follow the guidelines of hardware management capabilities, autonomy, performance and reliability, security, and high portability.",
What are the differences between edge native and cloud native?,"There are differences between edge native and cloud native in terms of application model, data model, elasticity, stability, scale, orchestration, management and control, network, security, hardware configuration and interaction with external resources.",
What are the similarities between edge native and cloud native?,"Both edge native and cloud native focus on portability, observability, manageability of applications and services, and support for multiple languages and frameworks.",
What are edge native applications?,"Edge-native applications are applications built using edge computing capabilities and are not suitable for running in the central cloud. They need to consider the unique characteristics of the edge, such as resource constraints, security, latency, and autonomy.",
What are the benefits of edge computing?,"Edge computing can reduce latency, manage bandwidth, enhance the security of private data, and operate stably under unreliable networks.",
What is the Edge Native Application Guidelines White Paper?,The Edge Native Application Guidelines white paper is a technical document on edge native applications that aims to provide guidance and guidelines for edge native applications.,
What are the open source projects for the directly integrated and indirectly called observability modules mentioned in this article?,"Direct integration includes but is not limited to: elastic/go-elasticsearch/v7, gorilla/mux, json-iterator/go, etc.; indirect calls include but is not limited to: go.uber.org/multierr, golang.org/x/crypto, sigs .k8s.io/structured-merge-diff/v4, etc.",
Which open source projects are used in the observability module called indirectly?,"Including but not limited to: go.uber.org/multierr, golang.org/x/crypto, sigs.k8s.io/structured-merge-diff/v4, etc.",
What open source projects are used in directly integrated observability modules?,"Including but not limited to: elastic/go-elasticsearch/v7, gorilla/mux, json-iterator/go, etc.",
What are the projects indirectly called by the global management module mentioned in this article?,"Including but not limited to: github.com/cenkalti/backoff/v4, github.com/decred/dcrd/dcrec/secp256k1/v4, github.com/emicklei/go-restful/v3, etc.",
What are the open source projects indirectly called by the container management module?,Open source projects indirectly called by the container management module include but are not limited to:\n-Azure/go ansiterm\n-Masterminds/semver/v3 \n-NYTimes/gziphandler \n-PuerkitoBio/purell \n-PuerkitoBio/urlesc \n-alicebob /gopher-json \n-asaskevich/govalidator ...\n13 in total.,
What are the open source projects that the container management module is directly integrated with?,Open source projects directly integrated with the container management module include but are not limited to:\n- DATA-DOG/go-sqlmock\n- Miniredis\n- cloudtty\n- clusterpedia-io/api\n- clusterpedia-io/client-go\ n- clusterpedia-io/fake-apiserver\n- Docker\n- fsnotify\n- yaml\n- go-openapi/runtime\n- go-openapi/strfmt\n- go-redis/redis\n- golang/ mock \n- google/go-cmp \n- google/uuid \n- gorilla/mux \n- grpc-ecosystem/go-grpc-middleware \n- grpc-ecosystem/grpc-gateway \n- heroku/docker registry client \n...\n41 in total.,
How to start using KWOK?,"You can check the official KWOK documentation for details, and use `kwokctl` to create and manage clusters.",
What are the limitations of KWOK to be aware of?,"Functional limitation: KWOK is not a kubelet. KWOK exhibits different behavior than kubelet in terms of Pod lifecycle management, volume mounting, and device plug-ins. \n- Accuracy limitations: KWOK does not yet accurately reflect the performance or behavior of real nodes under various workloads or environments. KWOK can only use some formulas to approximate real node behavior. \n- Security restrictions: KWOK does not enforce any security policies or security mechanisms on simulated nodes. KWOK assumes that all requests from kube-apiserver are authorized and valid.",
What are the usage scenarios?,"KWOK can be used for a variety of purposes, including learning, development, and testing. The tests include measuring how the application or controller scales when using nodes and Pods, creating a large number of Pods or services, creating a high-load environment on the cluster, simulating node failures or network partitions, etc.",
What are the advantages of using KWOK?,"Fast: You can create and delete clusters and nodes in almost real-time, without waiting for boot or preparation processes. \n- Good compatibility: KWOK can work with all tools or clients that are compatible with the Kubernetes API. \n- High portability: KWOK has no special software or hardware requirements. Once Docker or Nerdctl is installed, you can use the pre-built images to run KWOK. \n- High flexibility: You can configure different types of nodes, labels, stains, capacities, conditions, etc., and you can also configure different Pod behaviors and states to test different scenarios and edge use cases. \n-Good performance: You can simulate thousands of nodes on your laptop without consuming a lot of CPU or memory resources.",
What two tools does KWOK provide?,"`kwok` and `kwokctl`. Among them, `kwok` is responsible for simulating the life cycle of pseudo nodes, Pods and other Kubernetes API resources, and `kwokctl` is a CLI tool designed to simplify the creation and management of clusters composed of `kwok` simulated nodes.",
What is KWOK?,KWOK is the abbreviation of Kubernetes WithOut Kubelet. It is a toolkit that allows you to create a cluster of thousands of nodes in a few seconds.,
What will the future product development of "DaoCloud" be based on?,The future product development of "DaoCloud" will continue to be based on Kubernetes.,
What activities has been held by "DaoCloud"?,"""DaoCloud Daoke"" once held the ""Kubernetes Community Days Chengdu Station"" event, which gathered end users, contributors and technical experts from the open source community in the cloud native field to share multi-industry practices, popular open source projects, and community contributions about cloud native Experience and other rich content.",
What contributions has "DaoCloud Daoke" made in cloud native technology?,"""DaoCloud"" continues to contribute to the Kubernetes open source project in terms of cloud native technology. It is among the first manufacturers to pass the CNCF Kubernetes compatibility certification, and has become the first Kubernetes training partner in the world to obtain official CNCF certification.",
What are the features of "DaoCloud" products?,"The products of ""DaoCloud"" have the characteristics of high performance, high availability, simplicity and security.",
What is "DaoCloud Daoke"?,"""DaoCloud Daoke"" is an enterprise committed to making cloud native technologies represented by Kubernetes more smoothly and efficiently implemented into products and production practices.",
"As a CNCF Kubernetes compatibility certified manufacturer, what other honors does DaoCloud have?","DaoCloud became a CNCF-certified Kubernetes service provider and became the first Kubernetes training partner in the world to be officially certified by CNCF. At the 2022 Kubecon North America station, Kante Yin of DaoCloud won the Kubernetes 2022 Contributor Award.",
In what ways does DaoCloud contribute to Kubernetes?,"DaoCloud continues to increase participation and contribution in the Kubernetes community, and has open sourced outstanding projects such as Clusterpedia, Kubean, CloudTTY, KLTS.io, Merbridge, HwameiStor, Spiderpool, and Piraeus to continuously improve the Kubernetes ecosystem. In the past year, DaoCloud's cumulative contribution to the Kubernetes open source list ranked third in the world.",
In which industries does DaoCloud provide Kubernetes-based cloud native solutions? How's the effect?,"DaoCloud provides cloud-native solutions based on Kubernetes in industries such as finance, automobiles, and retail, and has achieved good results. For example, after Shanghai Pudong Development Bank deployed the Kubernetes platform, application deployment efficiency increased by 82%, the delivery cycle was shortened from half a year to one month, and the transaction success rate reached 99.999%.",
Why does DaoCloud choose to develop and deploy products based on Kubernetes?,"DaoCloud chose Kubernetes as the underlying container orchestration technology because in today's cloud native ecosystem, these functions are inseparable from Kubernetes as the underlying container orchestration technology. In addition, DaoCloud has also participated in contributing to many cloud native open source projects such as Kubernetes, continuing to increase participation and contribution in the cloud native open source community.",
What are the products and customer cases of "DaoCloud"?,"The product of ""DaoCloud"" is the DaoCloud Enterprise cloud-native application cloud platform, which includes application store, application delivery, microservice governance, observability, data services, multi-cloud orchestration, information creation heterogeneity, cloud-edge collaboration and other capabilities. Client cases include Shanghai Pudong Development Bank, Huatai Securities, Wells Fargo Fund, SAIC, Haier, Fudan University, Watsons, etc.",
Which Kubernetes versions does "DaoCloud Daoke" use?,"""DaoCloud"" uses Kubernetes 1.6.7, 1.10, 1.18 and supports versions 1.23 to 1.26.",
Why did "DaoCloud Daoke" choose Kubernetes as the container orchestration tool?,"As the de facto standard for container orchestration, Kubernetes has advantages such as diverse functions, stable performance, timely community support, and strong compatibility, and is widely adopted by large companies. Among the many technical solutions, ""DaoCloud"" adheres to Kubernetes as the core, and integrates surrounding best practices and advanced technologies on its basis to create a cloud-native solution suitable for its own product architecture.",
What is the primary challenge facing "DaoCloud"?,The primary challenge faced by "DaoCloud" is how to efficiently manage and schedule multiple containers and how to ensure normal communication between containers.,
What is "DaoCloud Daoke"?,"""DaoCloud"" is an innovative leader in the field of cloud native. Founded at the end of 2014, it is committed to building an open cloud operating system to empower enterprises' digital transformation.",
What is Prometheus?,Prometheus is an open source monitoring system that collects a variety of application and system performance metrics and provides flexible query and visualization capabilities.,
What are protobuf extensions?,The protobuf extension is an extension to the Google Protocol Buffers binary data serialization library that supports more types and features and provides better performance.,
What is SQL driver?,S,
What is OpenAPI?,"OpenAPI is a specification for describing RESTful APIs. It uses JSON or YAML format to describe API requests and responses, parameters, errors and other information. It helps generate tools such as client SDKs, server frameworks, and documentation.",
What items are included in the observability module of indirect calls?,"The observability module for indirect calls includes many projects, such as: json-patch, gofuzz, go-toml, protoc-gen-validate, etc.",
What items are included in the directly integrated observability module?,"The directly integrated observability module includes many projects, such as: gomock, go-sqlmock, go-elasticsearch, mux, json-iterator, ulid, errors, prom-label-proxy, client_golang, etc.",
What open source projects for observability modules are included in this list?,This list includes open source projects that integrate observability modules directly and indirectly.,
What kind of company is DaoCloud? What are your benchmark customers?,"DaoCloud is an innovative leader in the cloud native field and is committed to building an open cloud operating system to empower enterprises' digital transformation. Benchmark customers include Bank of Communications, Shanghai Pudong Development Bank, SAIC Group, Dongfeng Motor, Haier Group, Watsons, Golden Arches (McDonald's), etc.",
Why do organizations need OSPO?,"As more and more of the software we rely on is open source-based, organizations need a strategic approach to managing innovation and security risks.",
What is OSPO?,"OSPO, short for Open Source Program Office, is a strategic approach to organizing and managing open source projects and managing innovation and security risks.",
How is open source innovation developing in the game engine industry?,"The emergence of open source game engines, such as Bevy, Godot and O3DE, has led to the rapid development of open source innovation in the game engine industry.",
In what areas will RISC-V be widely used?,RISC-V will be widely used in the embedded and mobile space and is supported by Google as a "Tier 1" architecture for Android.,
In what areas will VSCode continue to grow and dominate the IDE space?,"VSCode will become a mainstream IDE for almost all major programming languages, even including embedded use in Codespaces and Gitpod.",
"In the field of generative AI, what issues might cause friction within and outside the open source community?","Generative AI can cause friction within and outside the open source community due to issues such as copyright, attribution, and compliance with open source foundation and company policies.",
What is generative artificial intelligence?,"Generative artificial intelligence refers to learning large amounts of data and generating new data through machine learning algorithms, such as the code generation tool CoPilot.",
Where is Kubernetes widely used?,"Kubernetes is used extensively both inside and outside the cloud-native ecosystem, including running in environments such as Chick-Fil-A restaurants, edge computing, and space.",
What is Kubernetes?,"Kubernetes is an open source container orchestration platform for automating the deployment, scaling, and management of containerized applications.",
What role does RISC-V play in the open source community?,RISC-V is an open source instruction set architecture that is advancing computer architecture as an open source community.,
What is VSCode?,"VSCode is a free, open source, and feature-rich cross-platform IDE developed by Microsoft.",
What moment of maturity is Kubernetes experiencing?,"Kubernetes is experiencing its Linux-flavored moment of maturity, expanding to run in new types of environments that the project was not originally designed for.",
Which trend will boutique cloud benefit from?,Boutique clouds will benefit from cost management trends.,
Will WebAssembly become the dominant form of computing?,"Yes, the author of the article believes that WebAssembly will become the dominant form of computing in the near future.",
What is Backstage? Which companies are using Backstage?,"Backstage is an open source project that aims to provide a developer portal to simplify the cloud native application development and deployment process. Traditional businesses like banks, airlines, and Spotify are using Backstage.",
Where does OpenTelemetry rank in CNCF's open source project velocity data?,OpenTelemetry ranks second in CNCF's open source project speed data.,
What is OpenTelemetry?,"OpenTelemetry is an open source project that aims to provide a consistent and scalable way to collect, process and export metrics, logs and distributed tracing data. It aims to unify data formats among various tools in the cloud native ecosystem.",
Which projects in CNCF have graduated and become mature GitOps tools?,The Argo and Flux projects have graduated in CNCF and become mature GitOps tools.,
What is GitOps?,GitOps is an approach to claiming and managing infrastructure and applications using Git as a single source of truth. It stores the declarative configuration of the application in a Git repository and uses CI/CD automation processes to implement these configurations.,
What is OpenTelemetry?,"OpenTelemetry is an open source project that aims to provide a unified observability standard for cloud native environments and supports multiple languages and platforms. It provides an SDK and tools for tracing, logging, and metrics collection.",
What is GreenOps?,GreenOps is a form of FinOps that focuses on the carbon footprint of cloud workloads and aims to optimize cloud resource usage to reduce environmental impact.,
What is SBOM?,"SBOM (Software Bill of Materials) is the basis for software supply chain security. It lists all components, version information and related metadata that make up the software.",
What is FinOps?,"FinOps is an approach that brings finance and operations teams together to optimize cloud cost, availability, and performance by monitoring and analyzing cloud resource usage.",
What is GitOps?,GitOps is an operation and maintenance model that uses Git as a single source of trust to achieve automated deployment and management by operating the Git repository of the Kubernetes cluster.,
Who is quoted in the article?,"Hemingway is quoted as saying: “Life leaves us bruised and bruised, but in the end, those wounded places must become our strongest places.”",
How many topics does this article cover?,"Two, namely ""I'll be fine in November"" and ""Relax control in December.""",
Who is the author of this article?,"Not mentioned, can't be sure.",
What is the architecture of DCE 5.0?,"The architecture of DCE 5.0 is divided into three layers:\n- User layer: Provides Web interface and API interface to support users to manage and operate the cluster;\n- Management layer: Responsible for cluster management, including node management, application management, monitoring and alarming etc., and provide API interfaces for the user layer to make calls;\n- Data layer: stores cluster configuration information and application data.",
What are the advantages of DCE 5.0?,"The advantages of DCE 5.0 include:\n-Full life cycle management: DCE 5.0 provides full life cycle management capabilities from application deployment to underlying infrastructure management;\n-Flexible expansion: DCE 5.0 supports multiple expansion methods, including clustering Capacity expansion, mirror warehouse expansion, node expansion, etc.;\n- One-stop service: DCE 5.0 integrates application market, mirror warehouse, node management, monitoring and alarm and other services to provide users with one-stop service;\n- High Availability: DCE 5.0 supports multi-node deployment and provides functions such as failover and load balancing, ensuring the high availability of the cluster;\n-Safety and reliability: DCE 5.0 supports a variety of security mechanisms, including user authentication, access control, etc., ensuring the platform safety and reliability.",
What are the main features of DCE 5.0?,"The main functions of DCE 5.0 include:\n-Application deployment: quickly deploy applications through the application market and custom images;\n-Application management: support application scaling, container restart, log viewing and other operations;\n-Application monitoring: provide Real-time monitoring and alarming enable users to discover and solve problems in a timely manner;\n- Image warehouse: Provides Docker image warehouse to facilitate users to store and manage their own images;\n- Node management: Supports node addition, node maintenance and other operations to ensure High availability of the cluster.",
What is MinimizeIPTablesRestore? How to control whether to turn on this function?,"MinimizeIPTablesRestore is a mechanism used to optimize kube-proxy performance. It only sends the rules changed in calling iptables-restore, rather than the entire rule set. This feature can be turned on or off by controlling the `--feature-gates=MinimizeIPTablesRestore=true/false` flag.",
Is allocation of volumes from snapshots across namespaces supported in Kubernetes? How to control turning on this function?,"Yes, allocating volumes from snapshots across namespaces is supported in Kubernetes. This feature can be turned on or off by controlling the `--feature-gates=CrossNamespaceVolumeDataSource=true/false` flag.",
What are CPUManager and DevicePlugins? What level of Feature Gate were they recently upgraded to?,CPUManager and DevicePlugins are a resource management method and a device plug-in management method in Kubernetes respectively. They have recently been upgraded to GA (General Availability) level Feature Gate.,
How to allow specifying whether a Pod should be added to the node's network namespace in Windows? What Feature Gate needs to be enabled for this function?,You can turn on or off the network namespace function that allows you to specify whether a Pod is added to a node in Windows by controlling the `--feature-gates=WindowsHostNetworking=true/false` flag.,
What is kubelet evented PLEG? How to enable this feature?,"The kubelet Evented PLEG is used to optimize the way of tracking Pod status in the node and reduce regular rotation training by relying on notifications from the container runtime interface (CRI) as much as possible, which will reduce the CPU usage of the kubelet. This feature can be turned on or off by controlling the `--feature-gates=EventedPLEG=true/false` flag.",
What problems is the optimization of Topology Manager used to solve? How to configure additional configurations of Topology Manager Policy?,"Topology Manager is optimized to better handle NUMA (Non-Uniform Memory Access) nodes. Additional configuration of Topology Manager Policy can be configured by setting the `topologyManagerPolicyOptions` field and the `--topology-manager-policy-options` flag in the kubelet config and kubectl commands respectively. Three new Alpha Feature Gates are added to control the configuration of Topology Manager Policy: `TopologyManagerPolicyOptions`, `TopologyManagerPolicyAlphaOptions` and `TopologyManagerPolicyBetaOptions`.",
What is dynamic resource allocation? How to enable this feature in Kubernetes?,"Dynamic resource allocation is a resource management method in Kubernetes that allows Pods to request special types of resources. These resources can be provided at the node level, cluster level, or according to other modes set by the user. This feature can be turned on or off by controlling the `--feature-gates=DynamicResourceAllocation=true/false` flag.",
What are the current issues with gzip compression in Kubernetes? How to disable response compression?,"Based on load testing and production data collected from thousands of production Kubernetes clusters, the community has observed that gzip compression in Kubernetes APIServer is currently sub-optimal. Response compression can be disabled by adding the `DisableCompression` field in kubeconfig, or by adding the `--disable-compression` flag in the kubectl command.",
How to set APIServer's `--aggregator-reject-forwarding-redirect` flag? What is the function of this flag?,You can allow the Aggregated API Server's redirect responses to continue to be forwarded by setting the `--aggregator-reject-forwarding-redirect=false` flag when the APIServer starts. The purpose of this flag is to allow end users to obtain a better service discovery and service routing experience.,
What is APISelfSubjectAttributesReview? How to control whether this function is turned on?,APISelfSubjectAttributesReview is an authorization mechanism in Kubernetes that checks whether the authentication subject of an API request has the necessary attributes required to perform the request. You can control whether this feature is enabled by controlling the `--feature-gates=SelfSubjectAPIReview=true/false` flag.,
What updates does Kubernetes v1.26 have for nodes (Kubelet)?,Kubernetes v1.26 updates to the node (Kubelet) mainly include adding new API resources related to dynamic resource allocation and supporting NUMA node optimization.,
Which Feature Gates have been removed in Kubernetes v1.26?,"According to the Kubernetes version iteration strategy, 11 Feature Gates were removed in Kubernetes v1.26. If you continue to set these Feature Gates in the component command, the component will not start properly.",
What new API resources have been added in Kubernetes v1.26?,"Kubernetes v1.26 adds multiple new API resources, including ValidatingAdmissionPolicy, SelfSubjectReview, and dynamic resource allocation related resources.",
What is an important KEP feature in Kubernetes v1.26?,"An important KEP feature is PodSchedulingReadiness, which controls when a Pod can be scheduled by the scheduler.",
What new features does Kubernetes v1.26 add?,"Kubernetes v1.26 adds multiple new features, including updates and optimizations in Kube APIServer, nodes, storage, network, resource control and coordination, scheduler and observability.",
What is online and offline hybrid deployment in Kubernetes?,"Online and offline mixed deployment refers to running offline business and online business at the same time in a Kubernetes cluster, by setting different types of services",
What is the off-peak scheduling strategy in Kubernetes?,"The off-peak scheduling strategy in Kubernetes is a strategy to control the number of jobs running at the same time, which can be achieved by setting the Pod's scheduling strategy. The purpose is to avoid running a large number of jobs when the system load is too high, and to allow more jobs to run during times when the system load is lower. You can use Kubernetes' scheduler or a third-party scheduler to implement off-peak scheduling.",
What is automatic expansion and contraction of cluster nodes in Kubernetes?,"The automatic expansion and contraction of cluster nodes refers to dynamically adjusting the number of nodes according to the resource usage of the cluster. By monitoring the resource usage of the cluster, the number of nodes is automatically adjusted according to the set threshold. For example, if the cluster's CPU usage exceeds the threshold, the number of nodes will be increased; if the cluster's CPU usage is below the threshold, the number of nodes will be reduced.",
What is vertical autoscaling in Kubernetes?,"Vertical autoscaling refers to allocating more resources (such as memory or CPU) to running Pods. By monitoring the resource usage of Pods, and automatically adjusting the container's resource requests and limits based on the set target usage. For example, if the Pod's CPU usage is low, the container's CPU requests and limits will be reduced; if the Pod's CPU usage is high, the container's CPU requests and limits will be increased.",
What is horizontal automatic scaling in Kubernetes?,"Horizontal automatic scaling refers to dynamically adjusting the number of copies of a Pod based on the actual load. By regularly monitoring the resource usage of the Pod, the number of copies is dynamically adjusted according to the set rules. For example, you can set the number of replicas to be increased when the CPU usage exceeds 80% and to be reduced when the CPU usage is below 50%.",
What is autoscaling in Kubernetes?,"The automatic scaling function in Kubernetes can dynamically adjust the number of replicas of Pods or nodes according to the actual load, including horizontal automatic expansion and contraction, vertical automatic expansion and contraction, and automatic expansion and contraction of cluster nodes.",
What is the difference between VPA and HPA? What are the advantages of VPA?,"VPA means allocating more resources to running Pods and automatically adjusting the container's resource requests and limits by monitoring the Pod's resource usage. Unlike HPA, VPA can improve node utilization, eliminate the need for benchmarking tasks, and adjust CPU and memory requests on the fly, among other advantages.",
How does HPA work? What are the advantages?,"HPA regularly monitors the resource usage of Pods and dynamically adjusts the number of Pod replicas based on set rules. The advantage of HPA is that it can improve the resource utilization of Pods in Deployment, ReplicationController, ReplicaSet or StatefulSet.",
What are the automatic scaling methods in Kubernetes?,"Kubernetes provides three methods of automatic expansion and contraction: horizontal automatic expansion and contraction (HPA), vertical automatic expansion and contraction (VPA) and cluster node automatic expansion and contraction (CA).",
Why do we need to set Request and Limit appropriately?,"Properly setting Request and Limit values for containers is crucial to optimizing resource utilization, which can avoid wasting resources and improve cluster efficiency. At the same time, it can also meet the resource needs of each team.",
What is resource utilization? How to measure resource utilization?,"Resource utilization refers to the degree to which computing resources are fully utilized, and is generally measured through indicator data such as CPU, memory, disk, and inbound and outbound bandwidth.",
What is the collection target (Objective) of Prometheus?,"Collection target (Objective) is the target captured by Prometheus. The collection target exposes its own status, or the agent exposes the operation and business indicators of the monitored object.",
What is an object? What role does it play in Kubernetes?,Objects are entities used in the Kubernetes system to represent part of the status of the cluster. The Kubernetes API uses these entities to represent the cluster status. Creating an object tells the Kubernetes system what you expect this portion of the cluster load to look like; this is the desired state of your cluster.,
What is Node? What role does it play in a cloud native platform?,"A node is a computer that can work together with other computers (or nodes) to complete a common task. In a cloud native platform, a node represents a unit that can perform work. Ideally, individual nodes are indistinguishable, since any node of a particular type should be indistinguishable from nodes of the same type.",
What is Network Policy? What does it do?,"Network Policy is a specification that stipulates how communication between Pod groups and between Pods and other network endpoints is allowed. Network policies help you declaratively configure which Pods and namespaces are allowed to communicate with each other, and which port numbers are specifically configured to execute each policy. It is implemented by network plug-ins provided by network providers and supported by Kubernetes.",
What is a namespace? What role does it play in Kubernetes?,"Namespace is an abstraction used by Kubernetes to support the isolation of resource groups in a single cluster. It is used to organize objects in the cluster and provides a method for dividing cluster resources. Resource names within the same namespace must be unique, but this is not required across namespaces. In the microservice engine, the namespace refers to the Nacos namespace, which is mainly used to achieve tenant-level configuration isolation.",
What is Mutual Transport Layer Security (mTLS)? What does it do?,"Mutual Transport Layer Security (mTLS) is a technology used to authenticate and encrypt messages sent between two services. mTLS is standard Transport Layer Security (TLS), but instead of verifying the identity of just one connection, it verifies both parties. It prevents attacks such as on-path attacks, spoofing attacks, credential stuffing, brute force attacks, and provides an additional layer of security to users entering the network or application. It is also able to authenticate connections from client devices that do not follow the login process, such as Internet of Things (IoT) devices.",
What is multi-tenant model? What benefits can it bring?,"Multi-tenant model refers to serving multiple tenants with a single software installation. A tenant can be a user, an application, or a group of users/applications operating the same software with their own data sets. Examples of multi-tenant software include Google Mail, Google Docs, Microsoft Office 365, Salesforce CRM, and Dropbox, among others. The multi-tenant model can bring benefits such as improved resource utilization efficiency, lower maintenance costs, and lower user software costs.",
What is a monolithic application? Why is it more advantageous to use a monolithic application than microservices until the product is proven successful?,"monolithic application is an architecture in which the entire application runs as a single executable file. It is more beneficial to use a monolithic application than microservices until the product is proven successful because a well-designed monolith adheres to lean principles and is the simplest way to get the application up and running. When the business value of a monolithic application is proven successful, it can be broken down into microservices. If a microservices-based application is made without the application generating any value, the effort will be wasted.",
What is kube-apiserver? What does it do?,"kube-apiserver is a control plane component that provides Kubernetes API services. It verifies and configures the data of API objects, including Pod, Service, replication controller, etc. The API server serves REST operations and provides a front-end to the cluster's shared state",
What is Kubernetes (k8s)? What features does it provide?,"Kubernetes, often abbreviated as k8s, is a popular open source tool for modern infrastructure automation. It manages applications running on distributed systems and bundles several infrastructure structures such as application instances, load balancers, persistent storage, etc. in a way that applications can be composed. Kubernetes enables automation and scalability, allowing users to deploy applications declaratively and in a repeatable manner. It provides resource management, load balancing, storage orchestration, automatic scaling, automatic recovery and other functions.",
What are Kops? What are its characteristics?,"Kops is a command-line tool that helps you create, destroy, upgrade, and maintain production-grade, high-availability Kubernetes clusters. Kops currently only supports AWS, and support for GCE, VMware vSphere and other third-party PaaS platforms is still in the Alpha stage. Building a cluster using Kops can achieve high reliability and support automated redundancy and self-healing functions.",
What is a job? What does it do?,"Job is a deterministic or batch task that needs to be run and completed. It creates one or more Pod objects and ensures that the specified number of Pods terminate successfully. As each Pod ends successfully, the Job will track and record the number of successful completions.",
What is Istio? What does it do?,"Istio is a free and open source service mesh that provides a unified way to integrate microservices, manage traffic, enforce policies and aggregate metrics data. When Istio is added to an application, there is no need to modify the application code. It is between the service and the network, forming what is commonly called a service mesh (Service Mesh), helping to simplify the management and monitoring of microservice architecture.",
What is an init container? What are its characteristics?,"The init container is one or more containers that must be run before the application container can run. The Init container must run to completion before the application container starts, and must run to completion before the next Init container starts. The init container helps ensure that the application starts correctly by completing some additional processing before the application starts.",
What is Ingress? What features does it provide?,"Ingress is an API object that manages external access to services in the cluster. The typical access method is HTTP. Ingress can provide functions such as load balancing, SSL termination, and name-based virtual hosting.",
What is Infrastructure as Code? What problems does it solve?,"Infrastructure as code is the practice of storing the definition of infrastructure as one or more files. By representing datacenter resources such as servers, load balancers, and subnets as code, it allows infrastructure teams to have a single source of truth for all configurations and allows them to manage the datacenter in CI/CD channels, enabling version control and deployment policies . Infrastructure as Code resolves the complexity, scaling bottlenecks, and misconfigurations that can be encountered when manually configuring infrastructure.",
What is Infrastructure as a Service (IaaS)? What benefits does it provide to users?,"Infrastructure as a Service (IaaS) is a cloud computing service model that provides physical or virtual computing, storage and network resources using a pay-as-you-go billing model. IaaS allows users to rent computing resources as needed and defer large capital expenditures while giving them the flexibility to scale up or down. IaaS reduces the initial costs of experimenting or trying new applications and provides tools to quickly deploy infrastructure. Users do not need to purchase and maintain computing and data center resources, thereby avoiding the problems of idleness and shortage of resources that may be faced when building traditional local facilities.",
In what year was Kubernetes 1.26 released?,The article does not clearly indicate this and cannot be determined.,
Which Beta features will be downgraded to Alpha in Kubernetes 1.25?,LocalStorageCapacityIsolationFS in Kubernetes 1.25,
Which GA feature gates have been removed in Kubernetes 1.25?,"Kubernetes 1.25 removes the GA feature gates of ServiceLoadBalancerClass, ServiceLBNodePortControl, CSRDuration, DefaultPodTopologySpread, NonPreemptingPriority, PodAffinityNamespaceSelector, PreferNominatedNode, PodOverhead, UnversionedKubeletConfigMap, IndexedJob and SuspendJob.",
What data will Kubernetes' kubeadm reset clear when executing?,"When kubeadm reset is executed, it will try its best to clean up old data. Old data will be cleared during each reset phase. The default etcd data directory will be deleted during the remove-etcd-member phase.",
What is a key in DSA format?,The key in DSA (Digital Signature Algorithm) format is a digital signature algorithm used to generate a public key and private key pair.,
Which GA feature gates have been removed in Kubernetes 1.25?,"Kubernetes 1.25 removes several GA feature gates, including ServiceLoadBalancerClass, ServiceLBNodePortControl, CSRDuration, DefaultPodTopologySpread, NonPreemptingPriority, PodAffinityNamespaceSelector, PreferNominatedNode, PodOverhead, UnversionedKubeletConfigMap, IndexedJob and SuspendJob.",
What fixes and enhancements have been made to the kubeadm command in Kubernetes 1.25?,"Kubernetes 1.25 has made many fixes and enhancements to the kubeadm command, including kubeadm join phase control-plane-preapare certs supporting the use of --dry-run operation, supporting the dry-run mode of sub-phases, and adding a new phase to kubeadm init - show -join-command etc.",
What enhancements and fixes have been made to the kubectl command in Kubernetes 1.25?,"Kubernetes 1.25 has made many enhancements and fixes to the kubectl command, including the kubectl wait command supporting setting non-existent fields in -o jsonpath=, kubectl api-resources adding the categories column and adding the --categories parameter when outputting -o wide. Supports filtering based on categories, moving kubectl alpha event to top-level command kubectl events, etc.",
How to use Health SLIs in Kubernetes?,"Add a new path /metrics/slis in each component to expose the service level indicator (ServiceLevelIndicator) in Prometheus format. Each component needs to expose two metrics, one is gauge and the other is counter.",
What are Health SLIs?,"Health SLIs are a standard format for exposing health information about Kubernetes components, including metric types, component names, health check status, and status counts.",
What are the kubectl command improvements in Kubernetes 1.26?,"The following improvements to the kubectl command are included in Kubernetes 1.26:\n- The kubectl wait command supports setting non-existent fields in -o jsonpath=, which is useful when some fields are set asynchronously. \n- kubectl api-resources adds the categories column when outputting -o wide, and adds the --categories parameter to support filtering based on categories. \n- kubectl alpha event moved to top-level command kubectl events. \n- Fixed kubectl rollout history --revision=<version>-o json|yaml <resource> command returning the latest version instead of the specified revision when outputting json/yaml. \n- Optimize the prompt message of the kubectl label --dry-run command to avoid users misunderstanding that the label has been set.",
What are the observability improvements in Kubernetes 1.26?,"KEP-3466 Kubernetes Component Health SLIs are added to Kubernetes 1.26, which adds a new path/metrics/slis for each component to expose service level indicators (ServiceLevelIndicator) in Prometheus format to facilitate monitoring and debugging of component health status. Alpha Feature Gate - ComponentSLIs needs to be turned on to use this feature.",
